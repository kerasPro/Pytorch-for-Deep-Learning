{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf5dcf7",
   "metadata": {},
   "source": [
    "# Depuración, Inspección y Modularización de Modelos\n",
    "\n",
    "Hasta ahora, te has centrado en construir y entrenar modelos. \n",
    "Pero en el mundo real, el primer intento de un modelo rara vez funciona a la perfección. \n",
    "A menudo te encontrarás con mensajes de error crípticos sobre dimensiones de tensores que no coinciden o, peor aún, tu modelo se ejecutará sin errores pero no producirá resultados significativos. \n",
    "\n",
    "Aquí es donde la **depuración (debugging), inspección y modularización** se convierten en habilidades esenciales. \n",
    "En este laboratorio, asumirás el papel de un investigador de modelos. \n",
    "Comenzarás con una Red Neuronal Convolucional (CNN) defectuosa y utilizarás técnicas de depuración sistemáticas para encontrar y corregir el error. Luego, aprenderás a refactorizar tu código para mayor claridad y reutilización, y finalmente, diseccionarás un modelo complejo pre-entrenado para comprender su funcionamiento interno.\n",
    "\n",
    "\n",
    "\n",
    "En este laboratorio, tú vas a:\n",
    "\n",
    "* **Depurar** una CNN defectuosa insertando sentencias de impresión (print) en el paso `forward` para identificar y corregir un error crítico de desajuste en la forma de los tensores.\n",
    "* **Refactorizar** el modelo corregido utilizando `nn.Sequential` para crear una arquitectura más limpia, modular y menos propensa a errores.\n",
    "* **Inspeccionar** las estadísticas de activación de tu modelo para realizar un control de coherencia (sanity check) ante problemas como la explosión o el desvanecimiento de gradientes.\n",
    "* **Explorar** la arquitectura de un modelo preexistente y complejo (`SqueezeNet`) para contar sus capas y analizar su distribución de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197b69c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb9f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import SqueezeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457aa723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129c668",
   "metadata": {},
   "source": [
    "## Carga de Datos\n",
    "\n",
    "Para depurar e inspeccionar un modelo de manera efectiva, primero necesitarás un conjunto de datos (dataset) con el cual trabajar.\n",
    "El objetivo de este laboratorio es practicar un flujo de trabajo de depuración e inspección de principio a fin, por lo que utilizarás un dataset sencillo que te permita concentrarte en la arquitectura del modelo en lugar de en un preprocesamiento de datos complejo.\n",
    "Para este propósito, utilizarás el dataset Fashion MNIST, que consiste en imágenes en escala de grises de prendas de vestir y sirve como un punto de referencia (benchmark) directo para tareas de clasificación de imágenes.\n",
    "Comenzarás cargando el dataset utilizando la librería torchvision de PyTorch y luego crearás un DataLoader para manejar eficientemente los datos en lotes (batches) durante el entrenamiento y la evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c4a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helper_utils.get_dataset()\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b101dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(iter(dataloader))\n",
    "print(\"Batch shape:\", img_batch.shape)  # Should be [batch_size, 1, 28, 28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74643a59",
   "metadata": {},
   "source": [
    "## Depuración a través del paso hacia adelante (forward pass)\n",
    "\n",
    "Al empezar a trabajar con un modelo nuevo, es común encontrarse con errores.\n",
    "Estos errores pueden deberse a diversas razones, como formas de tensores incorrectas, operaciones incompatibles o valores inesperados.\n",
    "A veces, el modelo puede ejecutarse sin errores pero producir salidas incorrectas.\n",
    "\n",
    "En esta sección, explorarás cómo depurar un modelo de PyTorch examinando su paso hacia adelante (forward pass)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573827f6",
   "metadata": {},
   "source": [
    "### Una primera exploración del modelo\n",
    "\n",
    "Ha llegado el momento de explorar el modelo.\n",
    "Este modelo es una red sencilla que cuenta con:\n",
    "* Un bloque convolucional: que consiste en una capa convolucional, una función de activación ReLU y una capa de max pooling.\n",
    "* Un bloque totalmente conectado (fully connected): que consiste en una capa lineal, una función de activación ReLU y una capa lineal final que genera las puntuaciones de las clases.\n",
    "\n",
    "Primero, instanciarás el modelo e intentarás ejecutar un paso hacia adelante (forward pass) con un lote (batch) del dataloader.\n",
    "Para obtener una salida más limpia en caso de errores, utilizarás `try/except` para capturar cualquier excepción que pueda surgir durante el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de59fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Bloque Convolucional\n",
    "        self.conv = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Bloque Fully Connected\n",
    "        # Para Fashion MNIST: las imágenes de entrada son 28x28,\n",
    "        # después de conv+pool: 32x14x14\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 clases para Fashion MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv(x)))\n",
    "        x = self.relu_fc(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9686ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn = SimpleCNN()\n",
    "\n",
    "try:\n",
    "    output = simple_cnn(img_batch)  \n",
    "except Exception as e:\n",
    "    print(f\"\\033[91mError during forward pass: {e}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02ac3c",
   "metadata": {},
   "source": [
    "De hecho, el modelo tal como se proporciona contiene algunos errores que requieren depuración.\n",
    "El mensaje que proporciona PyTorch cuando ocurre un error puede ser a veces críptico.\n",
    "Describe que dos matrices (`mat1` y `mat2`) no se pueden multiplicar y proporciona sus formas (shapes).\n",
    "Esto indica que hay un desajuste en las dimensiones de los tensores que se están multiplicando, lo cual es un problema común en las implementaciones de redes neuronales.\n",
    "\n",
    "Sin embargo, el mensaje de error no especifica **por qué y en qué parte** del modelo ocurre el error.\n",
    "Ahí es donde entra en juego el método `forward` del modelo.\n",
    "La naturaleza de grafo dinámico de PyTorch te permite insertar sentencias de impresión (print) o utilizar herramientas de depuración para inspeccionar los valores y las formas de los tensores en varios puntos del método `forward`.\n",
    "\n",
    "Definirás una nueva clase que hereda del modelo original y sobrescribirás el método `forward` para incluir sentencias de impresión que muestren la forma del tensor después de cada capa.\n",
    "Un primer intento podría ser separar explícitamente las capas en el método `forward` y, para cada capa:\n",
    "* Imprimir la forma del tensor antes de la capa (forma de entrada).\n",
    "* Imprimir la forma de algunos *parámetros de la capa* (por ejemplo, pesos y sesgos).\n",
    "* Imprimir la forma del tensor de *activación* después de la capa (forma de salida), que será la entrada para la siguiente capa.\n",
    "\n",
    "Ahora puedes ejecutar el paso hacia adelante nuevamente y observar las formas impresas para identificar dónde ocurre el desajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0697f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNDebug(SimpleCNN):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # La llamada super().__init__() anterior inicializa correctamente todas las capas de SimpleCNN\n",
    "        # No es necesario redefinir las capas aquí\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        print(\n",
    "            \" (Layer components) Conv layer parameters (weights, biases):\",\n",
    "            self.conv.weight.shape,\n",
    "            self.conv.bias.shape,\n",
    "        )\n",
    "        x_conv = self.relu(self.conv(x))\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After convolution and ReLU:\", x_conv.shape)\n",
    "        x_pool = self.pool(x_conv)\n",
    "        print(\"(Activation) After pooling:\", x_pool.shape)\n",
    "\n",
    "        print(\n",
    "            \"(Layer components) Linear layer fc1 parameters (weights, biases):\",\n",
    "            self.fc1.weight.shape,\n",
    "            self.fc1.bias.shape,\n",
    "        )\n",
    "\n",
    "        x_fc1 = self.relu_fc(self.fc1(x_pool))\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After fc1 and ReLU:\", x_fc1.shape)\n",
    "\n",
    "        print(\n",
    "            \"(Layer components) Linear layer fc2 parameters (weights, biases):\",\n",
    "            self.fc2.weight.shape,\n",
    "            self.fc2.bias.shape,\n",
    "        )\n",
    "        x = self.fc2(x_fc1)\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After fc2 (output):\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223eec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_debug = SimpleCNNDebug()\n",
    "\n",
    "try:\n",
    "    output_debug = simple_cnn_debug(img_batch)  \n",
    "except Exception as e:\n",
    "    print(f\"\\033[91mError during forward pass in debug model: {e}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee54db71-aa49-44df-8dc2-f4c9b0764e25",
   "metadata": {},
   "source": [
    "Esta es una salida mucho más clara. Ya puedes ver que todas las capas del bloque convolucional están funcionando bien y las formas son las esperadas (`batch_size=64` y `out_channels=32`).\n",
    "\n",
    "**El error ocurre en el bloque totalmente conectado (fully connected)**, específicamente en la primera capa lineal: `x_pool` tiene una forma de `[64, 32, 14, 14]`, pero la capa lineal espera una entrada de forma `[64, 6272]` (su matriz de pesos tiene una forma de `[128, 6272]`).\n",
    "\n",
    "Dado que la capa lineal `fc1` espera una entrada en 2D de forma `[batch_size, input_features]`, el tensor `x_pool` se está aplanando incorrectamente a un tensor 2D con forma `[64*32*14, 14]` antes de ser pasado a `fc1`. Esta no es la forma deseada y es lo que provoca el error de desajuste de dimensiones.\n",
    "\n",
    "Una vez que hayas identificado el problema, puedes solucionarlo añadiendo una operación de aplanado (flatten) antes de la primera capa lineal en el método `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNNFixed(SimpleCNN):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        print(\n",
    "            \" (Neuron components) Conv layer parameters (weights, biases):\",\n",
    "            self.conv.weight.shape,\n",
    "            self.conv.bias.shape,\n",
    "        )\n",
    "        x_conv = self.relu(self.conv(x))\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After convolution and ReLU:\", x_conv.shape)\n",
    "        x_pool = self.pool(x_conv)\n",
    "        print(\"(Activation) After pooling:\", x_pool.shape)\n",
    "\n",
    "        x_flattened = torch.flatten(\n",
    "            x_pool, start_dim=1\n",
    "        )  # Flatten all dimensions except batch\n",
    "        print(\"(Activation) After flattening:\", x_flattened.shape)\n",
    "\n",
    "        print(\n",
    "            \"(Neuron components) Linear layer fc1 parameters (weights, biases):\",\n",
    "            self.fc1.weight.shape,\n",
    "            self.fc1.bias.shape,\n",
    "        )\n",
    "\n",
    "        x_fc1 = self.relu_fc(self.fc1(x_flattened))\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After fc1 and ReLU:\", x_fc1.shape)\n",
    "\n",
    "        print(\n",
    "            \"(Neuron components) Linear layer fc2 parameters (weights, biases):\",\n",
    "            self.fc2.weight.shape,\n",
    "            self.fc2.bias.shape,\n",
    "        )\n",
    "        x = self.fc2(x_fc1)\n",
    "\n",
    "        print(\"===\")\n",
    "\n",
    "        print(\"(Activation) After fc2 (output):\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cfbd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed version\n",
    "simple_cnn_fixed = SimpleCNNFixed()\n",
    "\n",
    "output = simple_cnn_fixed(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c7a8b9",
   "metadata": {},
   "source": [
    "¡El problema ya está solucionado y el modelo se ejecuta sin errores! Puedes ver que las formas de los tensores son las esperadas después de cada capa, y la salida final tiene la forma correcta de `[64, 10]`, que corresponde al tamaño del lote (batch size) y al número de clases.\n",
    "\n",
    "Una vez que el modelo esté funcionando sin errores, puedes saltar a la siguiente sección para refactorizar el modelo utilizando `nn.Sequential`, logrando así una implementación más limpia y modular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300a1ca",
   "metadata": {},
   "source": [
    "## `nn.Sequential` para la Modularización\n",
    "\n",
    "El modelo ya funciona correctamente, pero el método `forward` es bastante extenso y repetitivo.\n",
    "Para que el código sea más limpio y modular, puedes utilizar `nn.Sequential` para definir los bloques convolucionales y totalmente conectados.\n",
    "\n",
    "De esta manera, obtienes varias ventajas:\n",
    "* **Modularidad**: Cada bloque se define como un módulo independiente, lo que facilita su comprensión y modificación.\n",
    "* **Reusabilidad**: Puedes reutilizar fácilmente los bloques en otros modelos o experimentos.\n",
    "* **Código más limpio**: El método `forward` se vuelve mucho más sencillo, ya que solo necesita llamar a los bloques de forma secuencial.\n",
    "* **Menos propenso a errores**: Al definir los bloques en un solo lugar, reduces las posibilidades de cometer errores al implementar el método `forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a442781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN2Seq(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Bloque Convolucional\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Bloque Fully Connected\n",
    "        # Para Fashion MNIST: las imágenes de entrada son 28x28,\n",
    "        # después de conv+pool: 32x14x14\n",
    "        flattened_size = 32 * 14 * 14\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(flattened_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10),  # 10 clases para Fashion MNIST\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = torch.flatten(x, start_dim=1)  # Aplanar todas las dimensiones excepto el batch\n",
    "        x = self.fc_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45aa791",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_seq = SimpleCNN2Seq()\n",
    "output = simple_cnn_seq(img_batch)\n",
    "\n",
    "print(\"Output shape from sequential model:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac6ddb",
   "metadata": {},
   "source": [
    "### Inspección Estadística de la Inicialización\n",
    "\n",
    "Una comprobación común al inspeccionar un modelo es observar las estadísticas de algunas activaciones para asegurarse de que se encuentran dentro de un rango razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN2SeqDebug(SimpleCNN2Seq):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # La llamada super().__init__() anterior inicializa correctamente todas las capas de SimpleCNN2Seq\n",
    "        # No es necesario redefinir las capas aquí\n",
    "\n",
    "    def get_statistics(self, activation):\n",
    "        mean = activation.mean().item()\n",
    "        std = activation.std().item()\n",
    "        min_val = activation.min().item()\n",
    "        max_val = activation.max().item()\n",
    "\n",
    "        print(f\" Media: {mean}\")\n",
    "        print(f\" Desv. Est.: {std}\")\n",
    "        print(f\" Mín: {min_val}\")\n",
    "        print(f\" Máx: {max_val}\")\n",
    "        return mean, std, min_val, max_val\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.conv_block(x)\n",
    "        x = torch.flatten(features, start_dim=1)  # Aplanar todas las dimensiones excepto el batch\n",
    "\n",
    "        print(\"Después de conv_block, las estadísticas de activación son:\")\n",
    "        self.get_statistics(features)\n",
    "\n",
    "        x = self.fc_block(x)\n",
    "        print(\"Después de fc_block, las estadísticas de activación son:\")\n",
    "        self.get_statistics(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd17319f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cnn_seq_debug = SimpleCNN2SeqDebug()\n",
    "\n",
    "for idx, (img_batch, _) in enumerate(dataloader):\n",
    "    if idx < 5:\n",
    "        print(f\"=== Batch {idx} ===\")\n",
    "        output_debug = simple_cnn_seq_debug(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b712b09",
   "metadata": {},
   "source": [
    "Esta es una comprobación de coherencia (sanity check) para asegurar que el modelo está inicializado correctamente y que las activaciones no están explotando o desvaneciéndose.\n",
    "*Estos problemas pueden derivar en un rendimiento de entrenamiento deficiente o en problemas de convergencia.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e4812",
   "metadata": {},
   "source": [
    "## Inspección del Modelo\n",
    "\n",
    "Con el modelo anterior funcionando correctamente, ahora inspeccionarás un modelo complejo preexistente de `torchvision.models`, como `SqueezeNet`.\n",
    "\n",
    "En esta sección, harás uso de las utilidades de inspección proporcionadas por PyTorch para explorar la arquitectura, las capas y los parámetros del modelo.\n",
    "Estas técnicas de inspección son fundamentales para una depuración efectiva y para realizar modificaciones informadas en tus diseños de redes neuronales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498a45e",
   "metadata": {},
   "source": [
    "### Descripción General de la Arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SqueezeNet model\n",
    "complex_model = SqueezeNet()\n",
    "\n",
    "print(complex_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61ff125",
   "metadata": {},
   "source": [
    "Para modelos complejos, imprimir la arquitectura completa del modelo puede resultar abrumador.\n",
    "En su lugar, puedes hacer uso de `named_children()` y `children()` para iterar a través de los bloques de nivel superior del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271910ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the main blocks\n",
    "for name, block in complex_model.named_children():\n",
    "    print(f\"El bloque {name} tiene un total de {len(list(block.children()))} capas:\")\n",
    "    \n",
    "    # List all children layers in the block\n",
    "    for idx, layer in enumerate(block.children()):\n",
    "        # Check if the layer is terminal (no children) or not\n",
    "        if len(list(layer.children())) == 0:\n",
    "            print(f\"\\t {idx} - Capa {layer}\")\n",
    "        # If the layer has children, it's a sub-block, then print only the number of children and its name\n",
    "        else:\n",
    "            layer_name = layer._get_name()  # Nombre más amigable para el usuario\n",
    "            print(f\"\\t {idx} - Sub-bloque {layer_name} con {len(list(layer.children()))} capas\")         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ac451a",
   "metadata": {},
   "source": [
    "Esto proporciona una visión general más limpia de la estructura del modelo, permitiéndote enfocarte en los componentes principales sin perderte en los detalles de cada capa individual.\n",
    "Ahora harás un \"zoom\" en uno de los módulos `Fire` para ver su estructura interna.\n",
    "\n",
    "Para ello, puedes usar `modules()` para iterar a través de todas las capas y sub-módulos del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_fire_module = complex_model.features[3]\n",
    "\n",
    "for idx, module in enumerate(first_fire_module.modules()):\n",
    "    # Avoid printing the top-level module itself\n",
    "    if idx > 0 :\n",
    "        print(module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a189bb",
   "metadata": {},
   "source": [
    "Ahora la arquitectura del modelo se imprime de forma ordenada, mostrando los componentes principales y sus configuraciones.\n",
    "Ahora puedes realizar algunas inspecciones específicas, como contar el número de tipos de capas específicos o calcular el número total de parámetros en el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52912d",
   "metadata": {},
   "source": [
    "### Inspección Detallada\n",
    "\n",
    "Ahora contarás cuántas capas `Conv2d` hay en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4718d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_layer = nn.Conv2d\n",
    "\n",
    "selected_layers = [layer for layer in complex_model.modules() if isinstance(layer, type_layer)]\n",
    "\n",
    "print(f\"Number of {type_layer.__name__} layers: {len(selected_layers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7a2914",
   "metadata": {},
   "source": [
    "Ahora contarás el número total de parámetros en el modelo.\n",
    "Esto te da una idea de la complejidad y la capacidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87da032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of parameters in the model\n",
    "total_params = sum(p.numel() for p in complex_model.parameters())\n",
    "print(f\"Total number of parameters in the model: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c5b1b",
   "metadata": {},
   "source": [
    "Ahora, puedes ir un paso más allá inspeccionando los parámetros de cada capa terminal (capas sin hijos) del modelo.\n",
    "Para cada capa terminal, imprimirás su nombre y el número total de parámetros que contiene.\n",
    "Esto ayuda a identificar qué capas contribuyen más al conteo de parámetros del modelo y puede ser útil para la optimización del modelo, el pruning, o para entender dónde reside la capacidad del mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "counting_params = {}\n",
    "\n",
    "# For each terminal layer print its number of parameters\n",
    "for layer in complex_model.named_modules():\n",
    "    n_children = len(list(layer[1].children()))\n",
    "    if n_children == 0:  # Terminal layer\n",
    "        layer_name = layer[0]\n",
    "        n_parameters = sum(p.numel() for p in layer[1].parameters())\n",
    "        counting_params[layer_name] = n_parameters\n",
    "        print(f\"Layer {layer_name} has {n_parameters} parameters\")\n",
    "\n",
    "# Plotting the distribution of parameters per layer\n",
    "helper_utils.plot_counting(counting_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afda7eac",
   "metadata": {},
   "source": [
    "# Conclusión\n",
    "\n",
    "Has depurado, refactorizado e inspeccionado con éxito modelos de PyTorch. \n",
    "En este laboratorio, viste de primera mano que el `forward` pass de un modelo no es una caja negra y que, al añadir sentencias de impresión estratégicamente, puedes diagnosticar y resolver errores comunes pero frustrantes como los desajustes de forma (shape mismatches).\n",
    "\n",
    "Has ido más allá de simplemente escribir código de modelos y ahora puedes hacerlos más robustos y legibles agrupando capas en bloques lógicos con **`nn.Sequential`**. \n",
    "Esta práctica de modularización hace que tus arquitecturas sean más fáciles de entender, reutilizar y adaptar. \n",
    "También aprendiste cómo realizar comprobaciones de coherencia (sanity checks) esenciales inspeccionando las estadísticas de activación y cómo explorar sistemáticamente cualquier modelo de PyTorch, por muy complejo que sea, utilizando utilidades de inspección como `.modules()` y `.named_children()`.\n",
    "\n",
    "Con estas habilidades fundamentales de depuración e inspección, estás bien preparado para desafíos más avanzados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-for-deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
