{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b21cfc0-db1b-4afd-b3a7-368cdc6daeb4",
   "metadata": {},
   "source": [
    "# Tarea de Programaci√≥n - Superando el Overfitting: Construyendo una CNN Robusta\n",
    "\n",
    "¬°Bienvenido a la tarea final de este curso! Has construido una base s√≥lida en PyTorch, pasando de tensores b√°sicos a una Red Neuronal Convolucional completa y funcional en un laboratorio anterior. Ese fue un primer paso esencial. Ahora, es momento de dar el siguiente paso y enfrentar un desaf√≠o que todo practicante de deep learning encuentra: tomar un modelo prometedor pero imperfecto y elevarlo.\n",
    "\n",
    "Tu modelo anterior mostr√≥ signos claros de overfitting, un obst√°culo com√∫n donde una red memoriza los datos de entrenamiento en lugar de aprender a generalizar. Esta tarea es tu misi√≥n para resolver ese problema, no solo ajustando un par√°metro, sino re-ingenierizando sistem√°ticamente todo tu pipeline de machine learning con un conjunto de herramientas y t√©cnicas profesionales.\n",
    "\n",
    "Para lograr esto, desplegar√°s una estrategia multifac√©tica, mejorando cada componente de tu configuraci√≥n:\n",
    "\n",
    "* **Mejorar el Data Pipeline** con un aumento de datos (data augmentation) m√°s potente para crear un conjunto de entrenamiento m√°s rico.\n",
    "\n",
    "* **Refactorizar la Arquitectura para la Modularidad**, creando `CNNBlocks` reutilizables para un c√≥digo m√°s limpio y escalable.\n",
    "\n",
    "* **Integrar Capas Avanzadas** como **Batch Normalization** para estabilizar el entrenamiento y mejorar la generalizaci√≥n.\n",
    "\n",
    "* **Desplegar una Estrategia de Regularizaci√≥n Robusta** utilizando **Dropout** y **Weight Decay** para combatir el overfitting directamente.\n",
    "\n",
    "¬°Comencemos y elevemos tu modelo al siguiente nivel!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7b4bb9-517f-4991-9d5e-962722e36105",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='submission'></a>\n",
    "\n",
    "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
    "\n",
    "* All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "* In each exercise cell, look for comments `### START CODE HERE ###` and `### END CODE HERE ###`. These show you where to write the solution code. **Do not add or change any code that is outside these comments**.\n",
    "\n",
    "* You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "\n",
    "* Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "* To submit your notebook for grading, first save it by clicking the üíæ icon on the top left of the page and then click on the `Submit assignment` button on the top right of the page.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06328542-e3ff-43b1-be7f-1cef351ba6ff",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Imports](#0)\n",
    "- [1 - Upgrading Your Data Pipeline](#1)\n",
    "    - [1.1 - Defining More Powerful Transformations](#1-1)\n",
    "        - **[Exercise 1 - define_transformations](#ex-1)**\n",
    "    - [1.2 - Assembling the Data Loaders](#1-2)\n",
    "    - [1.3 - Visualizing the Training Images](#1-3)\n",
    "- [2 - Building a Modular and Robust CNN](#2)\n",
    "    - [2.1 - The Power of Modularity: The CNNBlock](#2-1)\n",
    "        - [2.1.1 - BatchNorm2d Layer](#2-1-1)\n",
    "            - **[Exercise 2 - CNNBlock](#ex-2)**\n",
    "    - [2.2 - Assembling the Full CNN with Modular Blocks](#2-2)\n",
    "        - **[Exercise 3 - SimpleCNN](#ex-3)**\n",
    "- [3 - Training the Upgraded Model](#3)\n",
    "    - [3.1 - Configuring the Loss and Optimizer](#3-1)\n",
    "    - [3.2 - Implementing the Training and Validation Logic](#3-2)    \n",
    "        - **[Exercise 4 - train_epoch](#ex-4)**\n",
    "        - **[Exercise 5 - validate_epoch](#ex-5)**        \n",
    "- [4 - Beyond the Foundations: A Glimpse into the Next Level](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f583f9a-3bc9-4ef1-b846-6803314e4dd1",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33a321-ef93-4897-8b99-36f771c1ccb2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3762cc3c-c631-4ad4-a0dc-2ea2d88d471a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import helper_utils\n",
    "import unittests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1e750-6b47-4ce2-be85-b518be0e99d5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b66c5c-c3ae-40c2-a170-1c0e007e5876",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Mejorando tu Data Pipeline\n",
    "\n",
    "En el primer laboratorio de este m√≥dulo, construiste un potente clasificador CNN desde cero. Aunque funcion√≥, tambi√©n te encontraste con un obst√°culo cl√°sico del machine learning: el **overfitting**. Tu modelo comenz√≥ a memorizar los datos de entrenamiento en lugar de aprender a generalizar, un problema com√∫n cuando el rendimiento de un modelo en los datos de validaci√≥n se estanca o degrada.\n",
    "\n",
    "Tus resultados de entrenamiento de ese laboratorio probablemente produjeron un gr√°fico similar al de abajo. Ilustra perfectamente este desaf√≠o, mostrando los signos reveladores del overfitting. Observa de cerca la brecha cada vez mayor entre la **training loss**, que contin√∫a mejorando, y la **validation loss**, que se estanca o incluso empeora. Esta divergencia, junto con la **validation accuracy** alcanzando una meseta, es la evidencia cl√°sica de un modelo que est√° memorizando los datos de entrenamiento en lugar de aprender realmente a generalizar.\n",
    "\n",
    "![Lab 1 Training Plot](nb_image/lab_1_training_plot.png)\n",
    "\n",
    "\n",
    "\n",
    "Ahora enfrentar√°s este desaf√≠o directamente. El objetivo es doble: primero, resolver el overfitting, y segundo, llevar el rendimiento de tu modelo a nuevas alturas. Sin embargo, antes de poder mejorar la arquitectura del modelo, primero debes mejorar los datos de los que aprende.\n",
    "\n",
    "Una estrategia fundamental para construir modelos m√°s robustos es el **data augmentation**. Al crear versiones modificadas de tus im√°genes de entrenamiento, volte√°ndolas o rot√°ndolas, le ense√±as a tu modelo a reconocer sujetos en una variedad de condiciones. Esta t√©cnica es una primera l√≠nea de defensa crucial contra el overfitting. Tu primera tarea es construir un conjunto de transformaciones de imagen a√∫n m√°s potente para potenciar tu dataset.\n",
    "\n",
    "<a name='1-1'></a>\n",
    "### 1.1 - Definiendo Transformaciones m√°s Potentes\n",
    "\n",
    "Comencemos configurando los componentes esenciales para tu data pipeline. Empezar√°s definiendo los valores de normalizaci√≥n est√°ndar para el dataset CIFAR-100 y luego crear√°s los pipelines de transformaci√≥n propiamente dichos.\n",
    "\n",
    "* Define `cifar100_mean` y `cifar100_std`, los valores de media y desviaci√≥n est√°ndar para el dataset **CIFAR-100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5785e2-916d-4fbf-b753-85416867acaa",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Pre-calculated mean for each of the 3 channels of the CIFAR-100 dataset\n",
    "cifar100_mean = (0.5071, 0.4867, 0.4408)\n",
    "# Pre-calculated standard deviation for each of the 3 channels of the CIFAR-100 dataset\n",
    "cifar100_std = (0.2675, 0.2565, 0.2761)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f42d86-745f-4b98-a835-0f3311505ab3",
   "metadata": {},
   "source": [
    "Como aprendiste anteriormente, el pipeline de transformaciones de entrenamiento es donde aplicas el data augmentation. Para hacer tu modelo a√∫n m√°s robusto, esta vez a√±adir√°s una nueva t√©cnica a tu arsenal: `RandomVerticalFlip`. Aunque el volteo horizontal es com√∫n, a√±adir volteos verticales tambi√©n puede ayudar al modelo a aprender que la orientaci√≥n de un objeto no siempre es vertical, una caracter√≠stica √∫til para clasificar cosas como insectos o flores desde varios √°ngulos.\n",
    "\n",
    "\n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1 - define_transformations\n",
    "\n",
    "Tu tarea es definir dos pipelines de transformaci√≥n de im√°genes distintos utilizando `torchvision.transforms`.\n",
    "\n",
    "**Tu Tarea**:\n",
    "\n",
    "* **Para `train_transformations`**: Crea una composici√≥n de transformaciones para el dataset de entrenamiento.\n",
    ">\n",
    "    * Este pipeline debe incluir volteos aleatorios [horizontales](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomHorizontalFlip.html) y [verticales](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomVerticalFlip.html).\n",
    "    * Tambi√©n debe [rotar](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.RandomRotation.html) aleatoriamente las im√°genes hasta **15 grados**.\n",
    "    * Finalmente, debe convertir las im√°genes a [tensores](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html) de PyTorch y [normalizarlas](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) usando la `mean` y `std` proporcionadas.\n",
    ">\n",
    "* **Para `val_transformations`**: Crea un segundo pipeline, m√°s simple, para el dataset de validaci√≥n.\n",
    ">\n",
    "    * Este pipeline solo debe realizar los dos pasos esenciales: convertir im√°genes a [tensores](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.ToTensor.html) y [normalizarlos](https://docs.pytorch.org/vision/main/generated/torchvision.transforms.Normalize.html) con la misma `mean` y `std`.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Click to expand if you are stuck)</font></b></summary>\n",
    "\n",
    "Si est√°s atascado, aqu√≠ tienes un desglose m√°s detallado.\n",
    "\n",
    "Usar√°s `transforms.Compose([...])` para crear una lista de transformaciones para ambos pipelines. Todas las funciones requeridas son parte del m√≥dulo `transforms`.\n",
    "\n",
    "**Para `train_transformations`**:\n",
    "\n",
    "* Necesitas crear una lista de cinco objetos de transformaci√≥n dentro de `transforms.Compose`.\n",
    "\n",
    "* El primero es para volteos horizontales. La llamada se ve as√≠: `transforms.RandomHorizontalFlip()`.\n",
    "\n",
    "* Los siguientes dos para volteos verticales y rotaciones siguen un patr√≥n similar. Recuerda pasar `15` como argumento para la rotaci√≥n.\n",
    "\n",
    "* Las √∫ltimas dos transformaciones son:\n",
    "\n",
    "    * `llamar al m√©todo ToTensor del m√≥dulo transforms`\n",
    "\n",
    "    * `llamar al m√©todo Normalize del m√≥dulo transforms, pasando las variables mean y std`\n",
    "\n",
    "**Para `val_transformations`**:\n",
    "\n",
    "* Este pipeline es mucho m√°s simple y solo contiene los √∫ltimos dos pasos del pipeline de entrenamiento.\n",
    "\n",
    "* Tu lista dentro de `transforms.Compose` debe contener solo dos elementos:\n",
    "\n",
    "    * `primero, la transformaci√≥n para convertir una imagen a un tensor`\n",
    "\n",
    "    * `segundo, la transformaci√≥n para normalizar el tensor usando la mean y std dadas`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48268d0f-492c-4de7-9e4a-8b7c83b070ff",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: define_transformations\n",
    "\n",
    "def define_transformations(mean, std):\n",
    "    \"\"\"\n",
    "    Creates image transformation pipelines for training and validation.\n",
    "\n",
    "    Args:\n",
    "        mean (list or tuple): A sequence of mean values for each channel.\n",
    "        std (list or tuple): A sequence of standard deviation values for each channel.\n",
    "\n",
    "    Returns:\n",
    "        train_transformations (torchvision.transforms.Compose): El pipeline de \n",
    "                                                                transformaci√≥n de training.\n",
    "        val_transformations (torchvision.transforms.Compose): El pipeline de \n",
    "                                                              transformation de validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Define la secuencia de transformaciones para el training dataset.\n",
    "    \n",
    "    train_transformations = None.None([\n",
    "        # Voltear aleatoriamente la imagen de forma horizontal (probabilidad del 50%).\n",
    "        None,\n",
    "        # Voltear aleatoriamente la imagen de forma vertical (probabilidad del 50%).\n",
    "        None,\n",
    "        # Rotar la imagen en un √°ngulo aleatorio entre -15 y +15 grados.\n",
    "        None,\n",
    "        # Convertir la imagen de una PIL Image o NumPy array a un PyTorch tensor.\n",
    "        None,\n",
    "        # Normalizar el tensor con la mean y std proporcionadas.\n",
    "        None\n",
    "    ]) \n",
    "    \n",
    "    # Define la secuencia de transformaciones para el validation dataset.\n",
    "    val_transformations = None.None([\n",
    "        # Convertir la imagen de una PIL Image o NumPy array a un PyTorch tensor.\n",
    "        None,\n",
    "        # Normalizar el tensor con la mean y std proporcionadas.\n",
    "        None\n",
    "    ]) \n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Retornar ambos pipelines de transformaci√≥n.\n",
    "    return train_transformations, val_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e0001-3d4a-400f-aab4-2fccbc3f8d2f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the Transformations\n",
    "print(\"--- Verifying define_transformations ---\\n\")\n",
    "# Llamamos a la funci√≥n para verificar las transformaciones\n",
    "train_transform_verify, val_transform_verify = define_transformations(cifar100_mean, cifar100_std)\n",
    "\n",
    "\n",
    "print(\"Training Transformations:\")\n",
    "# Imprimimos las transformaciones de training para inspeccionarlas\n",
    "print(train_transform_verify)\n",
    "print(\"-\" * 30)\n",
    "print(\"\\nValidation Transformations:\")\n",
    "# Imprimimos las transformaciones de validation\n",
    "print(val_transform_verify)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77c564-95c0-4a74-8cdb-6775049c51b0",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Training Transformations:\n",
    "Compose(\n",
    "    RandomHorizontalFlip(p=0.5)\n",
    "    RandomVerticalFlip(p=0.5)\n",
    "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
    "    ToTensor()\n",
    "    Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))\n",
    ")\n",
    "------------------------------\n",
    "\n",
    "Validation Transformations:\n",
    "Compose(\n",
    "    ToTensor()\n",
    "    Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761))\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9bcb7-841d-4819-90eb-5107c8cb30f7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_1(define_transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21aa4a5-53aa-4bd1-a6b0-e0b77b7cd482",
   "metadata": {},
   "source": [
    "* Llama a la funci√≥n `define_transformations`, pasando `cifar100_mean` y `cifar100_std` como argumentos.\n",
    "* Esto devuelve dos pipelines de transformaci√≥n separados, los cuales se almacenan en las variables `train_transform` y `val_transform` para su uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d748fc54-639e-48a0-ad17-eb7b8636224a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create and store the training and validation transformation pipelines\n",
    "train_transform, val_transform = define_transformations(cifar100_mean, cifar100_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82a97e-14c7-4972-bf90-e1d689c7cf5e",
   "metadata": {},
   "source": [
    "<a name='1-2'></a>\n",
    "### 1.2 - Ensamblando los Data Loaders\n",
    "\n",
    "Con tus nuevos y potentes pipelines de transformaci√≥n definidos, es hora de preparar los datos para el entrenamiento. Primero especificar√°s las 15 clases objetivo y luego usar√°s tus transformaciones para cargar las im√°genes y envolverlas en objetos `DataLoader`, los cuales alimentar√°n los datos a tu modelo en batches (lotes).\n",
    "\n",
    "* Primero, define la lista `all_target_classes`.\n",
    "* Estas son las mismas clases de flores, mam√≠feros e insectos con las que trabajaste en el laboratorio anterior, asegurando que est√°s abordando el mismo problema de clasificaci√≥n, pero con un pipeline mejorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69421f3-9f65-4fb3-8369-19b01b25f3b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Define the full class list.\n",
    "all_target_classes = [\n",
    "    # Flowers\n",
    "    'orchid', 'poppy', 'rose', 'sunflower', 'tulip',\n",
    "    # Mammals\n",
    "    'fox', 'porcupine', 'possum', 'raccoon', 'skunk',\n",
    "    # Insects\n",
    "    'bee', 'beetle', 'butterfly', 'caterpillar', 'cockroach'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf919e-cee5-4365-805c-6c1aa3757f67",
   "metadata": {},
   "source": [
    "* A continuaci√≥n, llama a la funci√≥n `load_cifar100_subset`, pasando tu lista de clases (`all_target_classes`) y ambos pipelines de transformaci√≥n (`train_transform` y `val_transform`).\n",
    "* Esta funci√≥n se encarga de todo el proceso de carga y devuelve dos objetos `Dataset` de PyTorch, los cuales se almacenan en las variables `train_dataset` y `val_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d805d7-c101-4fa7-82c0-3baa99415f39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load the full datasets.\n",
    "train_dataset, val_dataset = helper_utils.load_cifar100_subset(all_target_classes, train_transform, val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e20de-b8e9-4dda-b1d8-f20919a48fc4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Con tus datasets preparados, el paso final es envolverlos en el `DataLoader` de PyTorch. Esta utilidad es esencial para alimentar los datos a tu modelo en lotes (batches) manejables.\n",
    "\n",
    "* Crea el `train_loader` para tus datos de entrenamiento.\n",
    "* Crea el `val_loader` para tus datos de validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0bbe4-86ea-497c-8de3-e60628571a92",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Set the number of samples to be processed in each batch\n",
    "batch_size = 64\n",
    "\n",
    "# Create a data loader for the training set, with shuffling enabled\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# Create a data loader for the validation set, without shuffling\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5a76f-f818-4ec5-8346-4e1ed788c469",
   "metadata": {},
   "source": [
    "<a name='1-3'></a>\n",
    "### 1.3 - Visualizando las Im√°genes de Entrenamiento\n",
    "\n",
    "Siempre es una buena pr√°ctica visualizar tus datos. La siguiente l√≠nea llama a una funci√≥n auxiliar para mostrar una cuadr√≠cula de im√°genes aleatorias de tu `train_loader`.\n",
    "\n",
    "Presta mucha atenci√≥n al resultado. Dado que estas im√°genes provienen del conjunto de entrenamiento, deber√≠as ver los efectos de tu pipeline de data augmentation en acci√≥n. Busca im√°genes que hayan sido volteadas aleatoriamente de forma horizontal, vertical o que est√©n rotadas. Esta es una excelente manera de confirmar que tus transformaciones est√°n funcionando como se espera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fafe015-9d6c-4e4d-ba82-5879d9ff6c27",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Visualize a grid of random training images\n",
    "helper_utils.visualise_images(train_loader, grid=(3, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fcb73f-bc90-43d1-acda-79022cd0645d",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Construyendo una CNN Modular y Robusta\n",
    "\n",
    "Con un data pipeline m√°s robusto en su lugar, tu siguiente paso es mejorar la arquitectura del modelo en s√≠. Refactorizar√°s la CNN original para que sea m√°s modular, eficiente y potente. Este es el siguiente paso fundamental para resolver el problema del overfitting y llevar el rendimiento de tu modelo a nuevas alturas.\n",
    "\n",
    "<a name='2-1'></a>\n",
    "### 2.1 - El Poder de la Modularidad: El CNNBlock\n",
    "\n",
    "En el laboratorio anterior, la arquitectura de tu modelo ten√≠a un patr√≥n repetitivo de capas de convoluci√≥n, activaci√≥n y pooling. Definir estas capas individualmente puede volverse repetitivo y hace que el modelo sea m√°s dif√≠cil de modificar. Un enfoque mucho mejor es agrupar estos patrones en un solo m√≥dulo reutilizable. Tu primera tarea es crear un `CNNBlock` que empaquete estas capas juntas. Este dise√±o modular hace que el c√≥digo de tu modelo principal sea significativamente m√°s limpio y f√°cil de manejar.\n",
    "\n",
    "<a name='2-1-1'></a>\n",
    "#### 2.1.1 - <code>[Capa BatchNorm2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)</code>\n",
    "\n",
    "Como parte de este nuevo bloque mejorado, tambi√©n introducir√°s una nueva y potente capa: `BatchNorm2d`. Esta capa es una t√©cnica fundamental para construir redes neuronales profundas modernas de alto rendimiento.\n",
    "\n",
    "Piensa en el Batch Normalization como un controlador de tr√°fico para los datos que fluyen entre las capas de tu red. Despu√©s de que una capa convolucional procesa un lote de im√°genes, las salidas (o activaciones) pueden tener distribuciones que var√≠an ampliamente de un lote al siguiente. `BatchNorm2d` interviene y normaliza estas activaciones dentro de cada mini-batch, ajust√°ndolas para que tengan una media y una desviaci√≥n est√°ndar consistentes. Luego utiliza dos par√°metros aprendibles para escalar y desplazar esta salida normalizada, permitiendo que la red misma aprenda la distribuci√≥n √≥ptima para los datos en ese punto.\n",
    "\n",
    "\n",
    "\n",
    "Este paso, aparentemente simple, proporciona tres beneficios profundos:\n",
    "\n",
    "* **Estabiliza y Acelera el Entrenamiento**: Al mantener la distribuci√≥n de los datos consistente entre capas, evita que las capas posteriores tengan que adaptarse constantemente a una entrada cambiante de las capas anteriores. Esta estabilidad te permite usar tasas de aprendizaje (learning rates) m√°s altas, lo que puede acelerar dr√°sticamente la rapidez con la que aprende tu modelo.\n",
    "\n",
    "* **Act√∫a como un Regularizador**: Debido a que las estad√≠sticas de normalizaci√≥n se calculan para cada mini-batch √∫nico, introduce una peque√±a cantidad de ruido en el proceso de entrenamiento. Este ruido hace que sea m√°s dif√≠cil para el modelo memorizar perfectamente los datos de entrenamiento, alent√°ndolo a aprender caracter√≠sticas m√°s generales y, por lo tanto, reduciendo el overfitting.\n",
    "\n",
    "* **Reduce la Sensibilidad a la Inicializaci√≥n**: La capa hace que tu modelo dependa menos de los pesos aleatorios espec√≠ficos con los que comienza, lo que lleva a resultados de entrenamiento m√°s confiables y repetibles.\n",
    "\n",
    "Al a√±adir `BatchNorm2d` a tu `CNNBlock`, no solo est√°s a√±adiendo otra capa; est√°s haciendo fundamentalmente que el proceso de entrenamiento de tu modelo sea m√°s estable, eficiente y robusto.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - CNNBlock\n",
    "\n",
    "Ahora implementar√°s la clase `CNNBlock`. Esta clase empaquetar√° las cuatro capas en un √∫nico m√≥dulo `nn.Sequential`.\n",
    "\n",
    "**Tu Tarea**:\n",
    "\n",
    "**Dentro del m√©todo `__init__`**:\n",
    "> * Necesitas definir un contenedor secuencial llamado `self.block`.\n",
    "> * Dentro de este contenedor <code>[nn.Sequential](https://docs.pytorch.org/docs/stable/generated/torch.nn.Sequential.html)</code>, a√±adir√°s las siguientes capas en orden:\n",
    ">    1. Una capa <code>[nn.Conv2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)</code>. Usa los argumentos `in_channels`, `out_channels`, `kernel_size`, y `padding` que se pasan al m√©todo `__init__`.\n",
    ">    2. Una capa <code>[nn.BatchNorm2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html)</code>. Esta capa necesita conocer el n√∫mero de canales de su entrada, que es la salida de la capa convolucional anterior.\n",
    ">    3. Una funci√≥n de activaci√≥n <code>[nn.ReLU](https://docs.pytorch.org/docs/stable/generated/torch.nn.ReLU.html)</code>.\n",
    ">    4. Una capa <code>[nn.MaxPool2d](https://docs.pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)</code>. Esto reducir√° la resoluci√≥n del mapa de caracter√≠sticas. Debes configurar tanto el `kernel_size` como el `stride` en `2`.\n",
    "\n",
    "**Dentro del m√©todo `forward`**:\n",
    "\n",
    "> * Este m√©todo realiza el paso hacia adelante (forward pass).\n",
    "> * Pasa el tensor de entrada `x` a trav√©s del `self.block` que definiste y devuelve el resultado.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Haz clic para expandir si est√°s atascado)</font></b></summary>\n",
    "\n",
    "Si buscas m√°s orientaci√≥n, aqu√≠ tienes un desglose detallado.\n",
    "\n",
    "**Para el m√©todo `__init__`**:\n",
    "\n",
    "* Est√°s definiendo una secuencia de capas. Toda la secuencia se asignar√° a `self.block`. La estructura comienza as√≠: `self.block = nn.Sequential(...)`.\n",
    "\n",
    "* Las capas se proporcionan como argumentos a `nn.Sequential`, separadas por comas.\n",
    "\n",
    "* **1. Capa Convolucional**: La primera capa es `nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding)`. Nota c√≥mo utiliza los par√°metros de la firma del m√©todo `__init__`.\n",
    "\n",
    "* **2. Capa Batch Norm**: La segunda capa es `nn.BatchNorm2d(...)`. Necesita un argumento: el n√∫mero de canales que normalizar√°. Esto es igual al n√∫mero de canales de salida de la capa anterior, que es `out_channels`.\n",
    "\n",
    "* **3. Capa ReLU**: La tercera capa es simplemente `nn.ReLU()`. No requiere ning√∫n argumento.\n",
    "\n",
    "* **4. Capa Max Pooling**: La capa final es `nn.MaxPool2d(...)`. Necesitas proporcionar el `kernel_size` y el `stride`. La llamada se ver√° as√≠: `nn.MaxPool2d(kernel_size=2, stride=2)`.\n",
    "\n",
    "**Para el m√©todo `forward`**:\n",
    "\n",
    "* Esta es una sola l√≠nea de c√≥digo. Simplemente necesitas llamar al m√≥dulo que creaste en el m√©todo `__init__` sobre el tensor de entrada.\n",
    "* El pseudoc√≥digo ser√≠a: `devolver el resultado de aplicar self.block a la entrada x`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea01e0f-9910-4de3-a431-7dcaac779817",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: CNNBlock\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Define un bloque convolucional simple para una CNN.\n",
    "\n",
    "    Este bloque consiste en una capa convolucional, batch normalization,\n",
    "    una activaci√≥n ReLU y una capa de max-pooling, agrupados como un m√≥dulo secuencial.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        \"\"\"\n",
    "        Inicializa las capas del CNNBlock.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): N√∫mero de canales en la imagen de entrada.\n",
    "            out_channels (int): N√∫mero de canales producidos por la convoluci√≥n.\n",
    "            kernel_size (int, opcional): Tama√±o del kernel de convoluci√≥n. Por defecto es 3.\n",
    "            padding (int, opcional): Zero-padding a√±adido a ambos lados de la entrada. Por defecto es 1.\n",
    "        \"\"\"\n",
    "        # Inicializa la clase padre nn.Module.\n",
    "        super(CNNBlock, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Define el contenedor secuencial para las capas del bloque.\n",
    "        self.block = None(\n",
    "            # Capa convolucional 2D para aplicar filtros aprendibles a la entrada.\n",
    "            None,\n",
    "            # Batch normalization para estabilizar y acelerar el entrenamiento.\n",
    "            None,\n",
    "            # Funci√≥n de activaci√≥n ReLU para introducir no-linealidad.\n",
    "            None,\n",
    "            # Capa de max pooling para reducir la resoluci√≥n del feature map y las dimensiones espaciales.\n",
    "            None\n",
    "        ) \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define el forward pass para el CNNBlock.\n",
    "\n",
    "        Args:\n",
    "            x: El tensor de entrada para el bloque.\n",
    "\n",
    "        Returns:\n",
    "            El tensor de salida despu√©s de pasar por el bloque.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Pasa el tensor de entrada a trav√©s del bloque secuencial de capas.\n",
    "        return None\n",
    "    \n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f3fe7b-7ec3-47fc-bbac-24d8b3090a9c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the CNNBlock\n",
    "print(\"--- Verifying CNNBlock ---\\n\")\n",
    "\n",
    "# Instancia el bloque con 3 canales de entrada y 16 canales de salida\n",
    "verify_cnn_block = CNNBlock(in_channels=3, out_channels=16)\n",
    "print(\"Estructura del Bloque:\\n\")\n",
    "print(verify_cnn_block)\n",
    "\n",
    "# Verifica la forma de la salida (output shape) despu√©s de un forward pass\n",
    "# Crea un tensor de entrada ficticio (batch_size=1, channels=3, height=32, width=32)\n",
    "dummy_input = torch.randn(1, 3, 32, 32)\n",
    "print(f\"\\nForma del tensor de entrada:  {dummy_input.shape}\")\n",
    "\n",
    "# Pasa el tensor ficticio a trav√©s del bloque\n",
    "output = verify_cnn_block(dummy_input)\n",
    "print(f\"Forma del tensor de salida: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd9cccb-9757-4c7f-a694-69c34d72cf9b",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Block Structure:\n",
    "\n",
    "CNNBlock(\n",
    "  (block): Sequential(\n",
    "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    ")\n",
    "\n",
    "Input tensor shape:  torch.Size([1, 3, 32, 32])\n",
    "Output tensor shape: torch.Size([1, 16, 16, 16])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db20525-3776-4cd3-a503-62675dfc6270",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_2(CNNBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75875497-665f-45cd-b237-ac8f54962ded",
   "metadata": {},
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 - Assembling the Full CNN with Modular Blocks\n",
    "\n",
    "Ahora que tienes un `CNNBlock` reutilizable, puedes ensamblar tu arquitectura `SimpleCNN` completa. Al usar tu nuevo bloque modular, ver√°s cu√°nto m√°s limpia y profesional se vuelve la definici√≥n de tu modelo. En lugar de definir muchas capas individuales para la parte convolucional de tu red, ahora definir√°s solo tres instancias de `CNNBlock`.\n",
    "\n",
    "Tu modelo constar√° de dos partes principales:\n",
    "\n",
    "* **Un extractor de caracter√≠sticas (Feature extractor)**: Una secuencia de tres CNNBlocks que aprender√°n a identificar patrones visuales en las im√°genes.\n",
    "* **Un clasificador (Classifier)**: Una secuencia de capas completamente conectadas (fully connected) que tomar√°n las caracter√≠sticas de los bloques convolucionales y realizar√°n la predicci√≥n final.\n",
    "\n",
    "En esta nueva versi√≥n, tambi√©n aumentar√°s la **tasa de dropout a `0.6`**. Este es otro paso importante en tu lucha contra el overfitting, ya que hace que el modelo sea menos propenso a depender de una sola caracter√≠stica.\n",
    "\n",
    "\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - SimpleCNN\n",
    "\n",
    "Ahora implementar√°s los m√©todos `__init__` y `forward` para la clase `SimpleCNN`. Utilizar√°s el `CNNBlock` que acabas de construir como el componente principal del cuerpo de la red.\n",
    "\n",
    "**Tu Tarea**:\n",
    "\n",
    "**Dentro del m√©todo `__init__`**:\n",
    "\n",
    "> * **Feature Extractor**:\n",
    ">\n",
    ">    * Instancia tres capas `CNNBlock` (`conv_block1`, `conv_block2`, `conv_block3`).\n",
    ">    * El primer bloque debe recibir una entrada de **3 canales** (para im√°genes RGB) y producir **32 canales de salida**.\n",
    ">    * Para los bloques subsiguientes, el n√∫mero de canales de entrada debe coincidir con el n√∫mero de canales de salida del bloque anterior. Duplicar√°s el n√∫mero de canales en cada paso `(3 -> 32 -> 64 -> 128)`.\n",
    "\n",
    "> * **Classifier**:\n",
    ">\n",
    ">    * Define un `self.classifier` usando un contenedor `nn.Sequential`.\n",
    ">    * Este contenedor debe tener las siguientes capas en orden:\n",
    ">        1. Una capa <code>[nn.Flatten](https://docs.pytorch.org/docs/stable/generated/torch.nn.Flatten.html)</code> para transformar el mapa de caracter√≠sticas 2D en un vector 1D.\n",
    ">        2. Una capa <code>[nn.Linear](https://docs.pytorch.org/docs/stable/generated/torch.nn.Linear.html)</code>. Debes calcular el n√∫mero correcto de caracter√≠sticas de entrada. Esto depende de la forma de salida del √∫ltimo `CNNBlock`. El tama√±o de salida de esta capa debe ser **512**.\n",
    ">        3. Una activaci√≥n `nn.ReLU`.\n",
    ">        4. Una capa <code>[nn.Dropout](https://docs.pytorch.org/docs/stable/generated/torch.nn.Dropout.html)</code> con una tasa de `0.6` para ayudar a prevenir el overfitting.\n",
    ">        5. Una capa `nn.Linear` final que mapee las **512 caracter√≠sticas** al **n√∫mero de clases de salida**.\n",
    "\n",
    "**Dentro del m√©todo `forward`**:\n",
    ">\n",
    ">    * Define el flujo de datos a trav√©s de la red.\n",
    ">    * Pasa la entrada `x` secuencialmente a trav√©s de `conv_block1`, luego `conv_block2` y finalmente `conv_block3`.\n",
    ">    * Finalmente, pasa la salida del √∫ltimo bloque convolucional a trav√©s de tu `classifier`.\n",
    ">    * Devuelve la salida final.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Haz clic para expandir si est√°s atascado)</font></b></summary>\n",
    "\n",
    "Si est√°s atascado, aqu√≠ tienes un desglose m√°s detallado para la implementaci√≥n.\n",
    "\n",
    "**Para el m√©todo `__init__`**:\n",
    "\n",
    "* **Bloques Convolucionales**:\n",
    ">    \n",
    "    * El primer bloque es una instanciaci√≥n directa: `self.conv_block1 = CNNBlock(in_channels=3, out_channels=32)`.\n",
    "    * Para el segundo bloque, los `in_channels` deben ser `32` (los `out_channels` del primero). Los `out_channels` ser√°n `64`. Sigue este patr√≥n para el tercer bloque.\n",
    ">\n",
    "* **Clasificador**:\n",
    "\n",
    "    * Comienza definiendo el contenedor secuencial: `self.classifier = nn.Sequential(...)`\n",
    "    **1. Capa Flatten**: La primera capa es `nn.Flatten()`. No recibe argumentos.\n",
    "    **2. Primera Capa Lineal**: Es `nn.Linear(in_features=..., out_features=512)`.\n",
    "        * Para encontrar los `in_features`, necesitas calcular el tama√±o del tensor aplanado. Las im√°genes de entrada son de 32x32. Cada `CNNBlock` contiene una capa `MaxPool2d` con un stride de 2, lo que reduce a la mitad la altura y el ancho. Despu√©s de tres bloques, las dimensiones ser√°n `32 ‚Üí 16 ‚Üí 8 ‚Üí 4`.\n",
    "        * El √∫ltimo `CNNBlock` produce 128 canales. Por lo tanto, el n√∫mero total de caracter√≠sticas es `128 * 4 * 4`.\n",
    "    **3. Capa ReLU**: A√±ade `nn.ReLU()`.\n",
    "    **4. Capa Dropout**: A√±ade `nn.Dropout(0.6)`.\n",
    "    **5. Capa Lineal Final**: Es `nn.Linear(in_features=512, out_features=num_classes)`.\n",
    "\n",
    "\n",
    "\n",
    "**Para el m√©todo `forward`**:\n",
    ">\n",
    "* Este m√©todo describe c√≥mo fluyen los datos de la entrada a la salida. Puedes usar la misma variable `x` y reasignarla despu√©s de cada paso.\n",
    "* El pseudoc√≥digo para la secuencia es:\n",
    "    * `x = pasar la entrada x a trav√©s de self.conv_block1`\n",
    "    * `x = pasar la nueva x a trav√©s de self.conv_block2`\n",
    "    * `x = pasar la nueva x a trav√©s de self.conv_block3`\n",
    "    * `x = pasar el mapa de caracter√≠sticas final a trav√©s de self.classifier`\n",
    "* Finalmente, devuelve `x`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f6ffc6-60f8-4758-b193-6d02ee0c26e1",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED CLASS: SimpleCNN\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Define una arquitectura CNN simple utilizando bloques modulares CNNBlocks.\n",
    "\n",
    "    Este modelo apila tres bloques convolucionales reutilizables seguidos de un\n",
    "    clasificador completamente conectado (fully connected) para realizar la clasificaci√≥n de im√°genes.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Inicializa las capas del modelo SimpleCNN.\n",
    "\n",
    "        Args:\n",
    "            num_classes (int): El n√∫mero de clases de salida para el clasificador.\n",
    "        \"\"\"\n",
    "        # Inicializa la clase padre nn.Module.\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "\n",
    "        # Define el primer bloque convolucional.\n",
    "        self.conv_block1 = None\n",
    "        # Define el segundo bloque convolucional.\n",
    "        self.conv_block2 = None\n",
    "        # Define el tercer bloque convolucional.\n",
    "        self.conv_block3 = None\n",
    "\n",
    "        # Define el bloque clasificador completamente conectado.\n",
    "        self.classifier = None(\n",
    "            # Aplana (Flatten) el feature map 3D (canales, alto, ancho) en un vector 1D.\n",
    "            None,\n",
    "            # Primera capa totalmente conectada (linear) que mapea las caracter√≠sticas aplanadas a una capa oculta.\n",
    "            None,\n",
    "            # Funci√≥n de activaci√≥n ReLU para introducir no-linealidad.\n",
    "            None,\n",
    "            # Capa Dropout para prevenir el overfitting estableciendo aleatoriamente una fracci√≥n de entradas a cero.\n",
    "            None,\n",
    "            # Capa totalmente conectada (linear) final que mapea la capa oculta a las clases de salida.\n",
    "            None\n",
    "        ) \n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define el forward pass del modelo SimpleCNN.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): El tensor de entrada que contiene un batch de im√°genes.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: El tensor de salida con los logits para cada clase.\n",
    "        \"\"\"\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Pasa la entrada a trav√©s del primer bloque convolucional.\n",
    "        x = None\n",
    "        # Pasa el resultado a trav√©s del segundo bloque convolucional.\n",
    "        x = None\n",
    "        # Pasa el resultado a trav√©s del tercer bloque convolucional.\n",
    "        x = None\n",
    "\n",
    "        # Pasa el feature map final a trav√©s del clasificador.\n",
    "        x = None\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Retorna el tensor de salida final.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e4cdd-f817-4e70-b13a-ec364107c0a6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Verify the SimpleCNN\n",
    "print(\"--- Verificando SimpleCNN ---\\n\")\n",
    "\n",
    "# Verifica la estructura del modelo\n",
    "# Instancia el modelo con 15 clases de salida\n",
    "verify_simple_cnn = SimpleCNN(num_classes=15)\n",
    "print(\"Estructura del Modelo:\\n\")\n",
    "print(verify_simple_cnn)\n",
    "\n",
    "# Verifica la forma de la salida (output shape) despu√©s de un forward pass\n",
    "# Crea un tensor de entrada ficticio (batch_size=64, channels=3, height=32, width=32)\n",
    "dummy_input = torch.randn(64, 3, 32, 32)\n",
    "print(f\"\\nForma del tensor de entrada:  {dummy_input.shape}\")\n",
    "\n",
    "# Pasa el tensor ficticio a trav√©s del modelo\n",
    "output = verify_simple_cnn(dummy_input)\n",
    "print(f\"Forma del tensor de salida: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7fd6a0-c734-4dc0-8deb-1e076b8f20f8",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Model Structure:\n",
    "\n",
    "SimpleCNN(\n",
    "  (conv_block1): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (conv_block2): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (conv_block3): CNNBlock(\n",
    "    (block): Sequential(\n",
    "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    )\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Flatten(start_dim=1, end_dim=-1)\n",
    "    (1): Linear(in_features=2048, out_features=512, bias=True)\n",
    "    (2): ReLU()\n",
    "    (3): Dropout(p=0.6, inplace=False)\n",
    "    (4): Linear(in_features=512, out_features=15, bias=True)\n",
    "  )\n",
    ")\n",
    "\n",
    "Input tensor shape:  torch.Size([64, 3, 32, 32])\n",
    "Output tensor shape: torch.Size([64, 15])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a9b977-bdd5-4eb2-84c6-ffd6a95ea1ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "**NOTA**: La prueba a continuaci√≥n eval√∫a tu clase `SimpleCNN`, la cual utiliza internamente el `CNNBlock` que implementaste en el ejercicio anterior. Si no pasaste la prueba del `Ejercicio 2 - CNNBlock`, ejecutar la siguiente celda probablemente devolver√° un error. ¬°Por favor, aseg√∫rate de que tu implementaci√≥n de `CNNBlock` sea correcta primero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f8ef1-40c7-403e-bbf4-add10dbc56ad",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_3(SimpleCNN, CNNBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73799749-5253-4867-96a6-dd311e39e2f4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Con tu clase `SimpleCNN` definida, el siguiente paso es crear una instancia del modelo.\n",
    "\n",
    "* Primero, determina din√°micamente el n√∫mero de clases obteniendo la longitud (length) del atributo `.classes` de tu `train_dataset`.\n",
    "* Luego, crea una instancia de tu modelo `SimpleCNN`, pasando la variable `num_classes` a su constructor. Esto asegura que la capa final de tu modelo tenga el tama√±o correcto para tu problema de 15 clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70233b-fbfe-4379-9a51-202e10740cec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleCNN(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77a33d-ac4d-4a8d-ad62-992ff1e7f086",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Entrenando el Modelo Mejorado\n",
    "\n",
    "Con tu data pipeline actualizado y tu arquitectura CNN modular completa, est√°s listo para comenzar el proceso de entrenamiento. En esta secci√≥n, configurar√°s las piezas finales de tu pipeline de entrenamiento: la funci√≥n de p√©rdida (loss function) y el optimizador. Luego, implementar√°s la l√≥gica central de entrenamiento y validaci√≥n que ejecutar√° tu experimento y revelar√° qu√© tan bien funciona tu nuevo modelo.\n",
    "\n",
    "<a name='3-1'></a>\n",
    "### 3.1 - Configurando la P√©rdida y el Optimizador\n",
    "\n",
    "Antes de poder entrenar el modelo, debes definir dos componentes clave: una funci√≥n de p√©rdida para medir el error y un optimizador para actualizar los pesos del modelo.\n",
    "\n",
    "* Para la funci√≥n de p√©rdida, seguir√°s utilizando `nn.CrossEntropyLoss`, la elecci√≥n est√°ndar para la clasificaci√≥n multiclase.\n",
    ">\n",
    "* Para el optimizador, usar√°s `Adam`, pero con una adici√≥n importante para combatir el overfitting: el `weight_decay` (decaimiento de pesos). \n",
    "    * El weight decay a√±ade una penalizaci√≥n a la funci√≥n de p√©rdida basada en la magnitud de los pesos del modelo. Esto motiva a la red a aprender valores de peso m√°s peque√±os y simples, lo que la hace m√°s robusta y menos propensa a memorizar los datos de entrenamiento. Esta es otra herramienta vital para mejorar la capacidad de generalizaci√≥n de tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85ea397-ac90-40dc-ba0d-0d3a13998de4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer for the model with weight_decay\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e693122-118a-4a43-84c6-cfbc7457d5e2",
   "metadata": {},
   "source": [
    "<a name='3-2'></a>\n",
    "### 3.2 - Implementando la L√≥gica de Entrenamiento y Validaci√≥n\n",
    "\n",
    "Ahora implementar√°s la l√≥gica central para entrenar y evaluar tu modelo. Esto se har√° en dos funciones separadas:\n",
    "\n",
    "* `train_epoch`: Para realizar una sola pasada sobre los datos de entrenamiento para actualizar el modelo.\n",
    "* `validate_epoch`: Para realizar una sola pasada sobre los datos de validaci√≥n para medir el rendimiento.\n",
    "\n",
    "\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - train_epoch\n",
    "\n",
    "Tu tarea es completar la l√≥gica central de entrenamiento dentro del bucle `for` de la funci√≥n `train_epoch`. Implementar√°s los cinco pasos fundamentales de una sola iteraci√≥n de entrenamiento.\n",
    "\n",
    "**Tu Tarea**:\n",
    "\n",
    "Dentro de la funci√≥n `train_epoch`, para cada batch de `images` y `labels`:\n",
    "\n",
    "* **Limpiar Gradientes**: \n",
    "    * Antes de calcular los gradientes para el batch actual, debes limpiar cualquier gradiente que haya quedado almacenado del batch anterior.\n",
    "* **Paso hacia adelante (Forward Pass)**: \n",
    "    * Alimenta el `model` con las `images` para obtener las predicciones de salida.\n",
    "* **Calcular la P√©rdida**: \n",
    "    * Usa la `loss_function` proporcionada para medir la diferencia entre las `outputs` del modelo y las `labels` reales.\n",
    "* **Paso hacia atr√°s (Backward Pass)**: \n",
    "    * Calcula los gradientes de la p√©rdida con respecto a todos los par√°metros del modelo. Esto tambi√©n se conoce como retropropagaci√≥n (backpropagation).\n",
    "* **Actualizar Par√°metros**: \n",
    "    * Usa el `optimizer` para ajustar los par√°metros del modelo bas√°ndote en los gradientes que acabas de calcular.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Haz clic para expandir si est√°s atascado)</font></b></summary>\n",
    "\n",
    "Si necesitas ayuda, aqu√≠ tienes una gu√≠a m√°s directa para cada paso.\n",
    "\n",
    "* **Limpiar Gradientes**: Esto se hace para evitar la acumulaci√≥n de gradientes entre batches.\n",
    "    * El pseudoc√≥digo es: `llamar al m√©todo zero_grad() en el optimizer`.\n",
    ">\n",
    "* **Forward Pass**: As√≠ es como obtienes las predicciones del modelo para el batch actual.\n",
    "    * El pseudoc√≥digo es: `outputs = llamar al model, pasando las images como argumento`.\n",
    ">\n",
    "* **Calcular la P√©rdida**: Comparas las predicciones del modelo con las etiquetas reales (ground truth).\n",
    "    * El pseudoc√≥digo es: `loss = llamar a la loss_function, pasando las outputs y labels como argumentos`.\n",
    ">\n",
    "* **Backward Pass**: Este paso calcula cu√°nto contribuy√≥ cada par√°metro del modelo a la p√©rdida global.\n",
    "    * El pseudoc√≥digo es: `llamar al m√©todo backward() en el tensor de la p√©rdida (loss)`.\n",
    ">     \n",
    "* **Update Parameters**: El optimizador utiliza los gradientes calculados para dar un peque√±o paso en la direcci√≥n que minimiza la p√©rdida.\n",
    "    * El pseudoc√≥digo es: `llamar al m√©todo step() en el optimizer`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d45c3-298b-4d4f-bb07-21efcb53c526",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: train_epoch\n",
    "\n",
    "def train_epoch(model, train_loader, loss_function, optimizer, device):\n",
    "    \"\"\"\n",
    "    Realiza una √∫nica √©poca de entrenamiento.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo de red neuronal a entrenar.\n",
    "        train_loader (torch.utils.data.DataLoader): El DataLoader para los datos de entrenamiento.\n",
    "        loss_function (callable): La funci√≥n de p√©rdida.\n",
    "        optimizer (torch.optim.Optimizer): El optimizador.\n",
    "        device (torch.device): El dispositivo (CPU o GPU) donde se realizar√° el entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        float: La p√©rdida (loss) promedio de entrenamiento para la √©poca.\n",
    "    \"\"\"\n",
    "    # Establece el modelo en modo de entrenamiento\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    # Itera sobre los lotes (batches) de datos en el training loader\n",
    "    for images, labels in train_loader:\n",
    "        # Mueve las im√°genes y etiquetas al dispositivo especificado (GPU o CPU)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        \n",
    "        # Limpia los gradientes de todas las variables optimizadas\n",
    "        None\n",
    "        # Realiza un forward pass para obtener las salidas del modelo\n",
    "        outputs = None\n",
    "        # Calcula la p√©rdida (loss)\n",
    "        loss = None\n",
    "        # Realiza un backward pass para calcular los gradientes\n",
    "        None\n",
    "        # Actualiza los par√°metros del modelo\n",
    "        None\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        # Acumula la p√©rdida de entrenamiento para el lote actual\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    # Calcula y retorna la p√©rdida promedio de entrenamiento para la √©poca\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865482be-7a13-40e1-a5d0-423ce72c6039",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Usa una funci√≥n auxiliar para realizar una prueba de integridad (sanity check) en la implementaci√≥n de train_epoch\n",
    "helper_utils.verify_training_process(SimpleCNN, train_loader, loss_function, train_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171df88c-ef49-498c-9e69-dd22e3497822",
   "metadata": {},
   "source": [
    "#### Expected Output (Approximately):\n",
    "\n",
    "```\n",
    "Training on 640 images for 5 epochs:\n",
    "\n",
    "Epoch [1/5], Loss: 2.6735\n",
    "Epoch [2/5], Loss: 2.3238\n",
    "Epoch [3/5], Loss: 2.0528\n",
    "Epoch [4/5], Loss: 1.8341\n",
    "Epoch [5/5], Loss: 1.7676\n",
    "\n",
    "Weight Update Check:\tModel weights changed during training.\n",
    "Loss Trend Check:\tLoss decreased from 2.6735 to 1.7676.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b341c2e8-d4ec-49a3-a8d6-fd4c557ac954",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_4(train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcfdcd6-5937-48a2-b27a-434e6e23ffc9",
   "metadata": {},
   "source": [
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - validate_epoch\n",
    "\n",
    "Tu tarea es completar la l√≥gica de validaci√≥n. Esto implica realizar un forward pass y luego calcular tanto la p√©rdida (loss) como el n√∫mero de predicciones correctas para determinar el accuracy.\n",
    "\n",
    "\n",
    "\n",
    "**Tu Tarea**:\n",
    "\n",
    "* **Desactivar el C√°lculo de Gradientes**:\n",
    ">\n",
    "    * Envuelve todo el bucle for dentro del context manager `torch.no_grad()`. Esto le indica a PyTorch que no calcule gradientes, lo que ahorra memoria y tiempo de c√≥mputo durante la validaci√≥n.\n",
    ">\n",
    "* **Dentro del bucle `for`**:\n",
    ">\n",
    "    * **Paso hacia adelante (Forward Pass)**: \n",
    "        * Al igual que en el entrenamiento, pasa las `images` a trav√©s del `model` para obtener sus `outputs`.        \n",
    "    * **Calcular la P√©rdida**: \n",
    "        * Usa la `loss_function` para calcular la `val_loss` entre las `outputs` y las `labels` reales.\n",
    "    * **Acumular la P√©rdida**: \n",
    "        * A√±ade la p√©rdida del lote a `running_val_loss`. Recuerda obtener el valor escalar del tensor de p√©rdida y escalarlo por el tama√±o del lote (batch size).\n",
    "    * **Obtener Predicciones**: \n",
    "        * Determina la clase predicha por el modelo para cada imagen del lote. Las `outputs` de tu modelo son puntuaciones brutas (logits). La clase con la puntuaci√≥n m√°s alta es la predicci√≥n del modelo. Debes encontrar el √≠ndice de esta puntuaci√≥n m√°xima.\n",
    "\n",
    "<details>\n",
    "<summary><b><font color=\"green\">Additional Code Hints (Haz clic para expandir si est√°s atascado)</font></b></summary>\n",
    "\n",
    "Si necesitas un poco m√°s de orientaci√≥n, aqu√≠ tienes una gu√≠a detallada.\n",
    "\n",
    "**Desactivar el C√°lculo de Gradientes**:\n",
    ">\n",
    "Este es un context manager en PyTorch. La estructura que necesitas es `with torch.no_grad():`. El bucle for debe estar indentado dentro de este bloque.\n",
    "\n",
    "**Dentro del bucle for**:\n",
    "   \n",
    "* **Forward Pass**: Es id√©ntico al bucle de entrenamiento. El pseudoc√≥digo es: `outputs = llamar al model, pasando las images como argumento`.\n",
    "\n",
    "* **Calcular la P√©rdida**: Tambi√©n es igual que en el bucle de entrenamiento. El pseudoc√≥digo es: `val_loss = llamar a la loss_function, pasando las outputs y labels como argumentos`.\n",
    "\n",
    "* **Acumular la P√©rdida**: Necesitas actualizar `running_val_loss`. El pseudoc√≥digo es: `running_val_loss += obtener el valor escalar de val_loss usando el m√©todo .item() * el n√∫mero de im√°genes en el lote actual`.\n",
    "\n",
    "* **Obtener Predicciones**: Necesitas encontrar la clase m√°s probable a partir de los logits de salida.\n",
    "\n",
    "    * La funci√≥n `torch.max()` es perfecta para esto. Debes llamarla sobre el tensor `outputs` a lo largo de la dimensi√≥n 1 (la dimensi√≥n de las clases).\n",
    "\n",
    "    * El pseudoc√≥digo es: `_, predicted = usar torch.max() en el tensor outputs, especificando la dimensi√≥n 1`.\n",
    "\n",
    "    * Ten en cuenta que `torch.max()` devuelve una tupla de (valores_m√°ximos, √≠ndices_m√°ximos). Solo necesitas el segundo elemento, los √≠ndices, que corresponden a las etiquetas de clase predichas.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a298e2fa-2676-4278-aded-195ece701f50",
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: validate_epoch\n",
    "\n",
    "def validate_epoch(model, val_loader, loss_function, device):\n",
    "    \"\"\"\n",
    "    Realiza una √∫nica √©poca de validaci√≥n.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo de red neuronal a validar.\n",
    "        val_loader (torch.utils.data.DataLoader): El DataLoader para los datos de validaci√≥n.\n",
    "        loss_function (callable): La funci√≥n de p√©rdida.\n",
    "        device (torch.device): El dispositivo (CPU o GPU) donde se realizar√° la validaci√≥n.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla que contiene la p√©rdida de validaci√≥n promedio y el accuracy de validaci√≥n.\n",
    "    \"\"\"\n",
    "    # Establece el modelo en modo de evaluaci√≥n\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Desactiva el c√°lculo de gradientes para la validaci√≥n\n",
    "    with None:\n",
    "        \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "        # Itera sobre los lotes (batches) de datos en el validation loader\n",
    "        for images, labels in val_loader:\n",
    "            # Mueve las im√°genes y etiquetas al dispositivo especificado\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            ### START CODE HERE ###\n",
    "            \n",
    "            # Realiza un forward pass para obtener las salidas del modelo\n",
    "            outputs = None\n",
    "            \n",
    "            # Calcula la p√©rdida de validaci√≥n para el lote\n",
    "            val_loss = None\n",
    "            # Acumula la p√©rdida de validaci√≥n\n",
    "            running_val_loss += None\n",
    "            \n",
    "            # Obtiene las etiquetas de clase predichas\n",
    "            _, predicted = None\n",
    "            \n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "            # Actualiza el n√∫mero total de muestras\n",
    "            total += labels.size(0)\n",
    "            # Actualiza el n√∫mero de predicciones correctas\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    # Calcula la p√©rdida de validaci√≥n promedio y el accuracy para la √©poca\n",
    "    epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = 100.0 * correct / total\n",
    "    \n",
    "    return epoch_val_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd09fa81-c19e-42d7-8e57-1f5115ce07b3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Usa una funci√≥n auxiliar para realizar una prueba de integridad (sanity check) en la implementaci√≥n de validate_epoch\n",
    "helper_utils.verify_validation_process(SimpleCNN, val_loader, loss_function, validate_epoch, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806cb5ef-efcd-4ca8-b4bf-c6fcd92b7fc2",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Return Types Check:\tFunction returned a float for loss and accuracy.\n",
    "Weight Integrity Check:\tModel weights were not changed during validation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2db780b-ccec-430d-86a1-32da4e685ece",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Test your code!\n",
    "unittests.exercise_5(validate_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc388c-da11-4823-a8cd-0cd15b521530",
   "metadata": {},
   "source": [
    "---\n",
    "# Submission Note\n",
    "\n",
    "Congratulations! You've completed the final graded exercise of this assignment.\n",
    "\n",
    "If you've successfully passed all the unit tests above, you've completed the core requirements of this assignment. Feel free to [submit](#submission) your work now. The grading process runs in the background, so it will not disrupt your progress and you can continue on with the rest of the material.\n",
    "\n",
    "**üö® IMPORTANT NOTE** If you have passed all tests within the notebook, but the autograder shows a system error after you submit your work:\n",
    "\n",
    "<div style=\"background-color: #1C1C1E; border: 1px solid #444444; color: #FFFFFF; padding: 15px; border-radius: 5px;\">\n",
    "    <p><strong>Grader Error: Grader feedback not found</strong></p>\n",
    "    <p>Autograder failed to produce the feedback...</p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "This is typically a temporary system glitch. The most common solution is to resubmit your assignment, as this often resolves the problem. Occasionally, it may be necessary to resubmit more than once. \n",
    ">\n",
    "If the error persists, please reach out for support in the [DeepLearning.AI Community Forum](https://community.deeplearning.ai/c/course-q-a/pytorch-for-developers/pytorch-fundamentals/560).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a6f04-4ce1-4056-bb89-8de3baac6c4d",
   "metadata": {},
   "source": [
    "Con las funciones individuales de entrenamiento y validaci√≥n completadas, ahora puedes integrarlas en el `training_loop` principal. Esta funci√≥n orquestar√° todo el proceso de entrenamiento durante un n√∫mero determinado de √©pocas e incluye una mejora fundamental.\n",
    "\n",
    "Un desaf√≠o com√∫n es que el rendimiento de un modelo puede alcanzar un m√°ximo y luego declinar si el entrenamiento contin√∫a por demasiado tiempo. Para solucionar esto, el `training_loop`:\n",
    "\n",
    "* **Monitorea** el accuracy de validaci√≥n al final de cada √©poca.\n",
    "* **Hace un seguimiento** del estado del modelo con mejor rendimiento visto hasta el momento.\n",
    "* Despu√©s de la √©poca final, autom√°ticamente **devuelve el modelo de su mejor √©poca individual**.\n",
    "\n",
    "Esto garantiza que siempre recuperes la versi√≥n de tu modelo que logr√≥ el mayor accuracy de validaci√≥n durante todo el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cd7b0a-1435-45f2-a03a-1e0240f238fb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def training_loop(model, train_loader, val_loader, loss_function, optimizer, num_epochs, device):\n",
    "    \"\"\"\n",
    "    Entrena y valida un modelo de red neuronal en PyTorch.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): El modelo a ser entrenado.\n",
    "        train_loader (torch.utils.data.DataLoader): DataLoader para el conjunto de entrenamiento.\n",
    "        val_loader (torch.utils.data.DataLoader): DataLoader para el conjunto de validaci√≥n.\n",
    "        loss_function (callable): La funci√≥n de p√©rdida (loss function).\n",
    "        optimizer (torch.optim.Optimizer): El algoritmo de optimizaci√≥n.\n",
    "        num_epochs (int): El n√∫mero total de √©pocas (epochs) para entrenar.\n",
    "        device (torch.device): El dispositivo (ej. 'cuda' o 'cpu') donde se ejecutar√° el entrenamiento.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Una tupla que contiene el mejor modelo entrenado y una lista de m√©tricas\n",
    "               (train_losses, val_losses, val_accuracies).\n",
    "    \"\"\"\n",
    "    # Mover el modelo al dispositivo especificado (CPU o GPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Inicializar variables para rastrear el modelo con mejor rendimiento\n",
    "    best_val_accuracy = 0.0\n",
    "    best_model_state = None\n",
    "    best_epoch = 0\n",
    "    \n",
    "    # Inicializar listas para almacenar las m√©tricas de entrenamiento y validaci√≥n\n",
    "    train_losses, val_losses, val_accuracies = [], [], []\n",
    "    \n",
    "    print(\"--- Entrenamiento Iniciado ---\")\n",
    "    \n",
    "    # Bucle sobre el n√∫mero especificado de √©pocas\n",
    "    for epoch in range(num_epochs):\n",
    "        # Realizar una √©poca de entrenamiento\n",
    "        epoch_loss = train_epoch(model, train_loader, loss_function, optimizer, device)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Realizar una √©poca de validaci√≥n\n",
    "        epoch_val_loss, epoch_accuracy = validate_epoch(model, val_loader, loss_function, device)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        # Imprimir las m√©tricas para la √©poca actual\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_accuracy:.2f}%\")\n",
    "        \n",
    "        # Verificar si el modelo actual es el mejor hasta ahora\n",
    "        if epoch_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = epoch_accuracy\n",
    "            best_epoch = epoch + 1\n",
    "            # Guardar el estado del mejor modelo en memoria (deep copy)\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    print(\"--- Entrenamiento Finalizado ---\")\n",
    "    \n",
    "    # Cargar los pesos del mejor modelo antes de retornar\n",
    "    if best_model_state:\n",
    "        print(f\"\\n--- Retornando el mejor modelo con {best_val_accuracy:.2f}% de validation accuracy, logrado en la √©poca {best_epoch} ---\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    # Consolidar todas las m√©tricas en una sola lista\n",
    "    metrics = [train_losses, val_losses, val_accuracies]\n",
    "    \n",
    "    # Retornar el modelo entrenado y las m√©tricas recolectadas\n",
    "    return model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3d5d0-9266-46c1-b113-821332732574",
   "metadata": {},
   "source": [
    "Todo est√° ahora en su lugar. El siguiente c√≥digo llamar√° a tu funci√≥n `training_loop` para dar inicio al proceso completo de entrenamiento y validaci√≥n.\n",
    "\n",
    "El modelo se entrenar√° durante **50 epochs**. Con las potentes t√©cnicas de regularizaci√≥n que has a√±adido (**Batch Normalization**, un **Dropout** incrementado y **Weight Decay**) y un **learning rate** m√°s peque√±o, el modelo est√° dise√±ado para aprender con mayor cautela. Este **training run** m√°s prolongado le da al modelo el tiempo suficiente para converger hacia una soluci√≥n robusta y generalizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ed632-494b-4368-a476-499a89e3d921",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Inicia el proceso de entrenamiento llamando a la funci√≥n training_loop\n",
    "trained_model, training_metrics = training_loop(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    val_loader=val_loader, \n",
    "    loss_function=loss_function, \n",
    "    optimizer=optimizer, \n",
    "    num_epochs=50, \n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Visualiza las m√©tricas de entrenamiento (p√©rdida y accuracy)\n",
    "print(\"\\n--- Plots de Entrenamiento ---\\n\")\n",
    "helper_utils.plot_training_metrics(training_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304397a3-f66a-4ec1-8618-cdadd9e2513b",
   "metadata": {},
   "source": [
    "**Analizando los Resultados**\n",
    "\n",
    "Observa de cerca los nuevos **plots** de entrenamiento y comp√°ralos con los del laboratorio anterior. La diferencia es notable.\n",
    "\n",
    "Las curvas de **training loss** y **validation loss** ahora se siguen muy de cerca, y la amplia brecha que se√±alaba el **overfitting** ha desaparecido. El **validation accuracy** muestra un ascenso mucho m√°s saludable y consistente. ¬°Esta es una evidencia clara de que has resuelto con √©xito el problema del **overfitting**! La combinaci√≥n de m√°s **data augmentation**, **Batch Normalization** y **Weight Decay** trabajaron juntos para crear un modelo que generaliza mucho mejor que antes.\n",
    "\n",
    "\n",
    "\n",
    "**La Meseta de Rendimiento (Performance Plateau)**\n",
    "\n",
    "El **validation accuracy** de tu modelo ahora alcanza su punto m√°ximo alrededor del 70%, lo cual es un resultado s√≥lido. Sin embargo, podr√≠as preguntarte por qu√© no alcanz√≥ el 90% o m√°s, especialmente con todas estas t√©cnicas avanzadas y un entrenamiento m√°s largo. La respuesta reside en qu√© tan efectivamente has utilizado las herramientas a tu disposici√≥n.\n",
    "\n",
    "Los fundamentos que has aprendido en este curso proporcionan una base s√≥lida para construir modelos de **deep learning**. Las t√©cnicas que ahora tienes a tu disposici√≥n, desde el **data augmentation** hasta el dise√±o modular y la regularizaci√≥n, son potentes. Aplicarlas correctamente es precisamente lo que te permiti√≥ resolver el problema inicial de **overfitting** y lograr este resultado s√≥lido. Esto demuestra que est√°s llevando al l√≠mite lo que se puede lograr con este **toolkit** fundamental.\n",
    "\n",
    "Has logrado algo significativo. Empezaste construyendo una **CNN** simple que sufr√≠a de un problema com√∫n y desafiante, y mejoraste sistem√°ticamente todo tu **pipeline** con t√©cnicas profesionales para crear este modelo final y robusto. ¬°Felicitaciones por un resultado exitoso!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887a2671-062f-484e-a1fb-1d77e7d99520",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - M√°s all√° de los Fundamentos: Un vistazo al siguiente nivel\n",
    "\n",
    "Has logrado tomar una **CNN** simple, diagnosticar sus fallos y mejorarla sistem√°ticamente hasta convertirla en un modelo robusto y con buena generalizaci√≥n. Has llevado el **toolkit** fundamental que has aprendido hasta sus l√≠mites para lograr un resultado s√≥lido.\n",
    "\n",
    "**¬øPero qu√© tal si este no es el l√≠mite? ¬øQu√© tal si hubiera otro camino?**\n",
    "\n",
    "**¬øQu√© tal si pudieras llevar el accuracy de tu modelo de un 70% a m√°s del 80% en este mismo dataset?**\n",
    "\n",
    "Echa un vistazo a los resultados de una estrategia de entrenamiento diferente y m√°s potente. Ejecuta la siguiente celda para verlo en acci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc717c9-7c50-4c32-8cad-df2d907eb7f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Importa la funci√≥n de vista previa que demuestra conceptos del pr√≥ximo curso\n",
    "from c2_preview.c2_preview import course_2_preview\n",
    "\n",
    "# Esta funci√≥n auxiliar ejecuta un bucle de entrenamiento utilizando una estrategia potente\n",
    "# que se ense√±ar√° en el pr√≥ximo curso. Ejecuta esta celda para ver los resultados mejorados en acci√≥n.\n",
    "trained_model = course_2_preview(\n",
    "    train_dataset, \n",
    "    val_dataset, \n",
    "    loss_function,\n",
    "    device,\n",
    "    num_epochs=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21517cc2-f6a6-4e16-93c9-bb58e8d79f68",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "Incre√≠ble, ¬øverdad? En solo **5 epochs**, el **validation accuracy** super√≥ el 80%, un nivel de rendimiento que tu modelo anterior no alcanz√≥ ni despu√©s de 50 **epochs**.\n",
    "\n",
    "**¬øC√≥mo es posible una mejora tan r√°pida y dram√°tica con exactamente los mismos datos?**\n",
    "\n",
    "Este resultado se logr√≥ combinando varias t√©cnicas potentes de siguiente nivel que dominar√°s en el pr√≥ximo curso. Esto fue solo un **preview**, pero la estrategia involucr√≥ tres mejoras clave:\n",
    "\n",
    "* **Uso de un Pre-trained Model**: Este es el cambio m√°s significativo. En lugar de empezar de cero con pesos aleatorios, este enfoque utiliza un modelo sofisticado que ya ha sido entrenado en millones de im√°genes. Ya posee una comprensi√≥n profunda de los patrones visuales, la cual puedes luego ajustar (**fine-tune**) para tu tarea espec√≠fica.\n",
    "\n",
    "* **Dynamic Learning Rate Scheduling**: En lugar de usar un √∫nico **learning rate** fijo, esta estrategia utiliza un *learning rate scheduler*. Esta herramienta ajusta inteligentemente el **learning rate** durante el entrenamiento, realizando actualizaciones m√°s grandes al principio y ajustes m√°s peque√±os y precisos a medida que el modelo se acerca a la mejor soluci√≥n.\n",
    "\n",
    "* **Transformaciones m√°s Avanzadas**: El pipeline de **data augmentation** utilizado para este **preview** tambi√©n fue m√°s avanzado. Incluy√≥ t√©cnicas dise√±adas espec√≠ficamente para estos modelos de alto rendimiento, asegurando que la red aprendiera de un conjunto de ejemplos de entrenamiento m√°s rico y desafiante.\n",
    "\n",
    "Estos conceptos son solo un vistazo de lo que viene despu√©s. Has construido una base incre√≠ble, y ahora est√°s listo para aprender las estrategias que los profesionales utilizan para lograr resultados **state-of-the-art** de manera r√°pida y eficiente.\n",
    "\n",
    "## Conclusi√≥n\n",
    "\n",
    "¬°Felicitaciones por completar esta tarea!\n",
    "\n",
    "Has navegado con √©xito a trav√©s de un **workflow** de **machine learning** completo y realista. Comenzaste con un modelo que sufr√≠a de **overfitting**, diagnosticaste el problema y luego aplicaste sistem√°ticamente una serie de t√©cnicas potentes y profesionales para resolverlo. No solo has mejorado un modelo; has aprendido un proceso repetible para refinar y fortalecer cualquier red neuronal que construyas en el futuro.\n",
    "\n",
    "Las habilidades que practicaste aqu√≠ (dise√±o modular, implementaci√≥n de regularizaci√≥n y an√°lisis de la din√°mica de entrenamiento) son fundamentales para construir modelos de **deep learning** efectivos. Has ido m√°s all√° de lo b√°sico y ahora est√°s equipado con el conocimiento pr√°ctico necesario para abordar problemas m√°s complejos del mundo real. ¬°Bien hecho!"
   ]
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "pytorch-for-deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
