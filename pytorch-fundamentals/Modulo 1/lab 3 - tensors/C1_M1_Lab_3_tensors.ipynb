{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors: The Core of PyTorch\n",
    "\n",
    "Has visto que el viaje de construir una red neuronal comienza con los datos. Antes de que puedas diseñar un modelo o iniciar el proceso de entrenamiento, debes reunir tu información y prepararla en un formato que el modelo pueda entender. En PyTorch, ese formato fundamental es el **tensor**. Los tensores son más que simples contenedores de datos; están optimizados para las operaciones matemáticas que impulsan el deep learning.\n",
    "\n",
    "Dominar los tensores es un paso vital. Muchos de los errores más comunes al construir modelos están relacionados con las formas (shapes), tipos o dimensiones de los tensores. Este laboratorio está diseñado para darte una base sólida en la manipulación de tensores, brindándote las habilidades para manejar datos de manera efectiva y depurar problemas con confianza.\n",
    "\n",
    "En este laboratorio, aprenderás cómo:\n",
    "\n",
    "* Crear tensores a partir de diferentes fuentes de datos como listas de Python y arrays de NumPy.\n",
    "\n",
    "* Cambiar la forma (reshape) y manipular las dimensiones de los tensores para preparar los datos para las entradas del modelo.\n",
    "\n",
    "* Usar técnicas de indexación (indexing) y segmentación (slicing) para acceder y filtrar partes específicas de tus datos.\n",
    "\n",
    "* Realizar las operaciones matemáticas y lógicas que forman la base de todos los cálculos de las redes neuronales.\n",
    "\n",
    "Al final de este notebook, tendrás las habilidades prácticas necesarias para gestionar con confianza los datos de cualquier proyecto de PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Tensor Creation\n",
    "\n",
    "El primer paso en cualquier pipeline de machine learning es preparar los datos para el modelo. En PyTorch, esto significa cargar tus datos en tensores. Verás que existen varias formas convenientes de crear tensores, ya sea que tus datos ya estén en otro formato o que necesites generarlos desde cero.\n",
    "\n",
    "### 1.1 From Existing Data Structures\n",
    "\n",
    "A menudo, tus datos brutos estarán en un formato común como una lista de Python, un array de NumPy o un DataFrame de pandas. PyTorch ofrece funciones directas para convertir estas estructuras en tensores, lo que hace que la etapa de preparación de datos sea más eficiente.\n",
    "\n",
    "* `torch.tensor()`: Esta función toma una entrada, como una lista de Python, para convertirla en un tensor.\n",
    "\n",
    "**Nota:** El tipo de números que utilices es importante. Si usas números enteros (integers), PyTorch los almacena como tales. Si incluyes decimales, se almacenarán como valores de punto flotante (floating point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DESDE LISTAS DE PYTHON: tensor([1, 2, 3])\n",
      "TIPO DE DATO DEL TENSOR: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Desde listas de Python\n",
    "x = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(\"DESDE LISTAS DE PYTHON:\", x)\n",
    "print(\"TIPO DE DATO DEL TENSOR:\", x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.from_numpy()`: Convierte un array de NumPy en un tensor de PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR DESDE NUMPY:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#  Desde un array de NumPy \n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "torch_tensor_from_numpy = torch.from_numpy(numpy_array)\n",
    "\n",
    "print(\"TENSOR DESDE NUMPY:\\n\\n\", torch_tensor_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Desde un DataFrame de pandas**: Pandas es una librería de Python para trabajar con datos organizados en filas y columnas, como un archivo CSV o una hoja de cálculo. Un DataFrame es la estructura de datos principal de pandas para almacenar este tipo de datos tabulares. Los DataFrames son una de las formas más comunes de cargar y explorar conjuntos de datos en machine learning, especialmente al leer archivos CSV. No existe una función directa para convertir un DataFrame a un tensor. El método estándar consiste en extraer los datos del DataFrame a un array de NumPy utilizando el atributo `.values` y luego convertir ese array en un tensor usando `torch.tensor()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME ORIGINAL:\n",
      "\n",
      "    distance_miles  delivery_time_minutes\n",
      "0            1.60                   7.22\n",
      "1           13.09                  32.41\n",
      "2            6.97                  17.47\n",
      "\n",
      "TENSOR RESULTANTE:\n",
      "\n",
      " tensor([[ 1.6000,  7.2200],\n",
      "        [13.0900, 32.4100],\n",
      "        [ 6.9700, 17.4700]], dtype=torch.float64)\n",
      "\n",
      "TIPO DE DATO DEL TENSOR: torch.float64\n"
     ]
    }
   ],
   "source": [
    "#  Desde un DataFrame de Pandas\n",
    "# Leer los datos del archivo CSV en un DataFrame\n",
    "df = pd.read_csv('./data.csv')\n",
    "\n",
    "# Extraer los datos como un array de NumPy desde el DataFrame\n",
    "all_values = df.values\n",
    "\n",
    "# Convertir los valores del DataFrame a un tensor de PyTorch\n",
    "tensor_from_df = torch.tensor(all_values)\n",
    "\n",
    "print(\"DATAFRAME ORIGINAL:\\n\\n\", df)\n",
    "print(\"\\nTENSOR RESULTANTE:\\n\\n\", tensor_from_df)\n",
    "print(\"\\nTIPO DE DATO DEL TENSOR:\", tensor_from_df.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - With Predefined Values\n",
    "\n",
    "A veces necesitas crear tensores para propósitos específicos, como inicializar los pesos (weights) y sesgos (biases) de un modelo antes de que comience el entrenamiento. PyTorch te permite generar rápidamente tensores llenos de valores provisionales como ceros, unos o números aleatorios, lo cual es útil para pruebas y configuración.\n",
    "\n",
    "* `torch.zeros()`: Crea un tensor lleno de ceros con las dimensiones especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR WITH ZEROS:\n",
      "\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# All zeros\n",
    "zeros = torch.zeros(2, 3)\n",
    "\n",
    "print(\"TENSOR WITH ZEROS:\\n\\n\", zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.ones()`: Crea un tensor lleno de unos con las dimensiones especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR WITH ONES:\n",
      "\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# All ones\n",
    "ones = torch.ones(2, 3)\n",
    "\n",
    "print(\"TENSOR WITH ONES:\\n\\n\", ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.rand()`: Genera un tensor con números aleatorios distribuidos uniformemente entre 0 y 1, basándose en las dimensiones especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1739648338311,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "sSTgintPHYdf",
    "outputId": "329cb9e4-fc9f-4e0b-c7e7-fc82d2662bf7",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM TENSOR:\n",
      "\n",
      " tensor([[0.9672, 0.1337, 0.5241],\n",
      "        [0.9266, 0.1321, 0.1371]])\n"
     ]
    }
   ],
   "source": [
    "# Random numbers\n",
    "random = torch.rand(2, 3)\n",
    "\n",
    "print(\"RANDOM TENSOR:\\n\\n\", random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - A partir de una secuencia\n",
    "\n",
    "Para situaciones en las que necesites generar una secuencia de puntos de datos, como un rango de valores para probar las predicciones de un modelo, puedes crear un tensor directamente desde esa secuencia.\n",
    "\n",
    "* `torch.arange()`: Crea un tensor 1D que contiene un rango de números desde el valor de inicio (start) especificado hasta uno menos que el valor final (stop) indicado, incrementando (si es positivo) o decrementando (si es negativo) según el valor de paso (step) especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARANGE TENSOR: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "# Rango de números\n",
    "range_tensor = torch.arange(0, 10, step=1)\n",
    "\n",
    "print(\"ARANGE TENSOR:\", range_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Cambio de Forma y Manipulación (Reshaping & Manipulating)\n",
    "\n",
    "Una fuente muy común de errores en proyectos de PyTorch es la discrepancia entre la forma (shape) de tus datos de entrada y la forma que tu modelo espera. Por ejemplo, un modelo suele estar diseñado para procesar un lote (batch) de datos, por lo que incluso si quieres hacer una sola predicción, debes darle forma a tu tensor de entrada para que parezca un lote de uno. Dominar el \"reshaping\" de tensores es un paso clave para construir y depurar modelos de manera efectiva.\n",
    "\n",
    "### 2.1 - Comprobación de las Dimensiones de un Tensor\n",
    "\n",
    "El primer paso para solucionar una discrepancia de forma es entender las dimensiones actuales de tu tensor. Comprobar el shape es tu herramienta principal de depuración. Te indica cuántas muestras (samples) tienes y cuántas características (features) hay en cada muestra.\n",
    "\n",
    "* `torch.Tensor.shape`: Un atributo que devuelve un objeto `torch.Size` detallando el tamaño del tensor a lo largo de cada dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# A 2D tensor\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Cambio de las Dimensiones de un Tensor\n",
    "\n",
    "Una vez que identificas una discrepancia de forma (shape mismatch), necesitas corregirla. Una tarea frecuente es añadir una dimensión a una sola muestra de datos para crear un lote de tamaño uno (batch of size one) para tu modelo, o eliminar una dimensión después de completar una operación por lotes.\n",
    "\n",
    "* **Añadir Dimensión:** `torch.Tensor.unsqueeze()` inserta una nueva dimensión en el índice especificado.\n",
    "    * *Nota cómo el shape cambiará de `[2, 3]` a `[1, 2, 3]` y el tensor queda envuelto en un par adicional de corchetes `[]`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "TENSOR CON DIMENSIÓN AÑADIDA EN EL ÍNDICE 0:\n",
      "\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "\n",
      "FORMA DEL TENSOR: torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Añadir dimensión\n",
    "expanded = x.unsqueeze(0)  #  Añadir dimensión en el índice 0\n",
    "\n",
    "print(\"\\nTENSOR CON DIMENSIÓN AÑADIDA EN EL ÍNDICE 0:\\n\\n\", expanded)\n",
    "print(\"\\nFORMA DEL TENSOR:\", expanded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Eliminar Dimensión:** `torch.Tensor.squeeze()` elimina las dimensiones que tengan un tamaño de 1.\n",
    "    * *Esto revierte la operación unsqueeze, eliminando el `1` del shape y quitando un par de corchetes exteriores*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPANDED TENSOR:\n",
      "\n",
      " tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]]])\n",
      "\n",
      "FORMA DEL TENSOR: torch.Size([1, 2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "TENSOR CON DIMENSIÓN ELIMINADA:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "FORMA DEL TENSOR: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "print(\"EXPANDED TENSOR:\\n\\n\", expanded)\n",
    "print(\"\\nFORMA DEL TENSOR:\", expanded.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "#  Eliminar dimensión \n",
    "squeezed = expanded.squeeze()\n",
    " \n",
    "print(\"\\nTENSOR CON DIMENSIÓN ELIMINADA:\\n\\n\", squeezed)\n",
    "print(\"\\nFORMA DEL TENSOR:\", squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Reestructuración (Restructuring)\n",
    "\n",
    "Más allá de simplemente añadir o eliminar dimensiones, es posible que necesites cambiar completamente la estructura de un tensor para que coincida con los requisitos de una capa u operación específica dentro de tu red neuronal.\n",
    "\n",
    "* **Cambio de forma (Reshaping):** `torch.Tensor.reshape()` cambia la forma de un tensor a las dimensiones especificadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "AFTER PERFORMING reshape(3, 2):\n",
      "\n",
      " tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Reshape\n",
    "reshaped = x.reshape(3, 2)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING reshape(3, 2):\\n\\n\", reshaped)\n",
    "print(\"\\nTENSOR SHAPE:\", reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Transposición (Transposing):** `torch.Tensor.transpose()` intercambia las dimensiones especificadas de un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([2, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "AFTER PERFORMING transpose(0, 1):\n",
      "\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "\n",
      "TENSOR SHAPE: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"\\nTENSOR SHAPE:\", x.shape)\n",
    "print(\"-\"*45)\n",
    "\n",
    "# Transpose\n",
    "transposed = x.transpose(0, 1)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING transpose(0, 1):\\n\\n\", transposed)\n",
    "print(\"\\nTENSOR SHAPE:\", transposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Combinación de Tensores (Combining Tensors)\n",
    "\n",
    "En la etapa de preparación de datos, es posible que necesites combinar datos de diferentes fuentes o fusionar lotes (batches) separados en un conjunto de datos más grande.\n",
    "\n",
    "* `torch.cat()`: Une una secuencia de tensores a lo largo de una dimensión existente. Nota: Todos los tensores deben tener la misma forma (shape) en las dimensiones distintas a la que se está concatenando."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A:\n",
      "\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "TENSOR B:\n",
      "\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "---------------------------------------------\n",
      "\n",
      "CONCATENATED TENSOR (dim=1):\n",
      "\n",
      " tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Create two tensors to concatenate\n",
    "tensor_a = torch.tensor([[1, 2],\n",
    "                         [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6],\n",
    "                         [7, 8]])\n",
    "\n",
    "# Concatenate along columns (dim=1)\n",
    "concatenated_tensors = torch.cat((tensor_a, tensor_b), dim=1)\n",
    "\n",
    "\n",
    "print(\"TENSOR A:\\n\\n\", tensor_a)\n",
    "print(\"\\nTENSOR B:\\n\\n\", tensor_b)\n",
    "print(\"-\"*45)\n",
    "print(\"\\nCONCATENATED TENSOR (dim=1):\\n\\n\", concatenated_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Indexación y Segmentación (Indexing & Slicing)\n",
    "\n",
    "Una vez que tienes tus datos en un tensor, a menudo necesitarás acceder a partes específicas de ellos. Ya sea que estés tomando una única predicción para inspeccionar su valor, separando tus características de entrada (features) de tus etiquetas (labels), o seleccionando un subconjunto de datos para análisis, la indexación y la segmentación son las herramientas adecuadas para el trabajo.\n",
    "\n",
    "### 3.1 - Acceso a los Elementos\n",
    "\n",
    "Estas son las técnicas fundamentales para extraer datos de un tensor y funcionan de manera muy similar a cómo accederías a los elementos en una lista estándar de Python.\n",
    "\n",
    "* **Indexación Estándar (Standard Indexing)**: Acceso a elementos individuales o filas completas utilizando índices enteros (por ejemplo, `x[0]`, `x[1, 2]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING SINGLE ELEMENT AT [1, 2]: tensor(7)\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING ENTIRE ROW [1]: tensor([5, 6, 7, 8])\n",
      "-------------------------------------------------------\n",
      "\n",
      "INDEXING ENTIRE LAST ROW ([-1]): tensor([ 9, 10, 11, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a 3x4 tensor\n",
    "x = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12]\n",
    "])\n",
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get a single element at row 1, column 2\n",
    "single_element_tensor = x[1, 2]\n",
    "\n",
    "print(\"\\nINDEXING SINGLE ELEMENT AT [1, 2]:\", single_element_tensor)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the entire second row (index 1)\n",
    "second_row = x[1]\n",
    "\n",
    "print(\"\\nINDEXING ENTIRE ROW [1]:\", second_row)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last row\n",
    "last_row = x[-1]\n",
    "\n",
    "print(\"\\nINDEXING ENTIRE LAST ROW ([-1]):\", last_row, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Segmentación (Slicing)**: Extracción de sub-tensores utilizando la notación `[inicio:fin:paso]` (por ejemplo, `x[:2, ::2]`).\n",
    "    * *Nota: El índice de fin (end) no se incluye en el resultado.*\n",
    "* El slicing se puede utilizar para acceder a columnas completas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SLICING FIRST TWO ROWS ([0:2]):\n",
      "\n",
      " tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SLICING THIRD COLUMN ([:, 2]]): tensor([ 3,  7, 11])\n",
      "-------------------------------------------------------\n",
      "\n",
      "EVERY OTHER COLUMN ([:, ::2]):\n",
      "\n",
      " tensor([[ 1,  3],\n",
      "        [ 5,  7],\n",
      "        [ 9, 11]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "LAST COLUMN ([:, -1]): tensor([ 4,  8, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the first two rows\n",
    "first_two_rows = x[0:2]\n",
    "\n",
    "print(\"\\nSLICING FIRST TWO ROWS ([0:2]):\\n\\n\", first_two_rows)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Get the third column of all rows\n",
    "third_column = x[:, 2]\n",
    "\n",
    "print(\"\\nSLICING THIRD COLUMN ([:, 2]]):\", third_column)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Every other column\n",
    "every_other_col = x[:, ::2]\n",
    "\n",
    "print(\"\\nEVERY OTHER COLUMN ([:, ::2]):\\n\\n\", every_other_col)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Last column\n",
    "last_col = x[:, -1]\n",
    "\n",
    "print(\"\\nLAST COLUMN ([:, -1]):\", last_col, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Combinación de Indexación y Segmentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "FIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\n",
      "\n",
      " tensor([[3, 4],\n",
      "        [7, 8]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "# Combining slicing and indexing (First two rows, last two columns)\n",
    "combined = x[0:2, 2:]\n",
    "\n",
    "print(\"\\nFIRST TWO ROWS, LAST TWO COLS ([0:2, 2:]):\\n\\n\", combined, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **`.item()`**: Extrae el valor de un tensor de un solo elemento como un número estándar de Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SINGLE-ELEMENT TENSOR: tensor(7)\n",
      "---------------------------------------------\n",
      "\n",
      ".item() PYTHON NUMBER EXTRACTED: 7\n",
      "TYPE: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"SINGLE-ELEMENT TENSOR:\", single_element_tensor)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Extract the value from a single-element tensor as a standard Python number\n",
    "value = single_element_tensor.item()\n",
    "\n",
    "print(\"\\n.item() PYTHON NUMBER EXTRACTED:\", value)\n",
    "print(\"TYPE:\", type(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Indexación Avanzada\n",
    "\n",
    "Para una selección de datos más compleja, como filtrar tu conjunto de datos basándose en una o más condiciones, puedes utilizar técnicas de indexación avanzada.\n",
    "\n",
    "* **Máscara Booleana (Boolean Masking)**: Uso de un tensor booleano para seleccionar elementos que cumplen una cierta condición (por ejemplo, `x[x > 5]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "MÁSCARA (VALORES > 6):\n",
      "\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False,  True,  True],\n",
      "        [ True,  True,  True,  True]]) \n",
      "\n",
      "VALORES DESPUÉS DE APLICAR LA MÁSCARA: tensor([ 7,  8,  9, 10, 11, 12]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "#  Indexación booleana usando comparaciones lógicas\n",
    "mask = x > 6\n",
    "\n",
    "print(\"MÁSCARA (VALORES > 6):\\n\\n\", mask, \"\\n\")\n",
    "\n",
    "# Aplicando enmascaramiento booleano\n",
    "mask_applied = x[mask]\n",
    "\n",
    "print(\"VALORES DESPUÉS DE APLICAR LA MÁSCARA:\", mask_applied, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Indexación \"Fancy\" (Fancy Indexing)**: Uso de un tensor de índices para seleccionar elementos específicos de una manera no contigua."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL TENSOR:\n",
      "\n",
      " tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "SPECIFIC ELEMENTS USING INDICES:\n",
      "\n",
      " tensor([[ 2,  4],\n",
      "        [10, 12]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL TENSOR:\\n\\n\", x)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "#  Indexación fancy\n",
    "\n",
    "#  Obtener la primera y tercera filas\n",
    "row_indices = torch.tensor([0, 2])\n",
    "\n",
    "# Obtener la segunda y cuarta columnas\n",
    "col_indices = torch.tensor([1, 3]) \n",
    "\n",
    "# Obtiene valores en (0,1), (0,3), (2,1), (2,3)\n",
    "get_values = x[row_indices[:, None], col_indices]\n",
    "\n",
    "print(\"\\nELEMENTOS ESPECÍFICOS USANDO ÍNDICES:\\n\\n\", get_values, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Operaciones Matemáticas y Lógicas (Mathematical & Logical Operations)\n",
    "\n",
    "En su esencia, las redes neuronales realizan cálculos matemáticos. Un solo neurón, por ejemplo, calcula una suma ponderada de sus entradas y añade un sesgo (bias). PyTorch está optimizado para realizar estas operaciones de manera eficiente en tensores completos a la vez, lo que hace que el entrenamiento sea tan rápido.\n",
    "\n",
    "### 4.1 - Aritmética\n",
    "\n",
    "Estas operaciones son la base de cómo una red neuronal procesa los datos. Verás cómo PyTorch maneja cálculos elemento por elemento (element-wise) y utiliza una potente función llamada \"broadcasting\" para simplificar tu código.\n",
    "\n",
    "* **Operaciones elemento por elemento (Element-wise Operations)**: Operadores matemáticos estándar (`+`, `*`) que se aplican a cada elemento de forma independiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B tensor([4, 5, 6])\n",
      "------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING ELEMENT-WISE ADDITION: tensor([5, 7, 9]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Element-wise addition\n",
    "element_add = a + b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE ADDITION:\", element_add, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B tensor([4, 5, 6])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING ELEMENT-WISE MULTIPLICATION: tensor([ 4, 10, 18]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Element-wise multiplication\n",
    "element_mul = a * b\n",
    "\n",
    "print(\"\\nAFTER PERFORMING ELEMENT-WISE MULTIPLICATION:\", element_mul, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Producto Punto (`torch.matmul()`)**: Calcula el producto punto (dot product) de dos vectores o matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "TENSOR B: tensor([4, 5, 6])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "AFTER PERFORMING DOT PRODUCT: tensor(32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TENSOR A:\", a)\n",
    "print(\"TENSOR B:\", b)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Dot product\n",
    "dot_product = torch.matmul(a, b)\n",
    "\n",
    "print(\"\\nAFTER PERFORMING DOT PRODUCT:\", dot_product, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Broadcasting**: La expansión automática de tensores más pequeños para que coincidan con la forma (shape) de tensores más grandes durante las operaciones aritméticas.\n",
    "    * El broadcasting permite realizar operaciones entre tensores con formas compatibles, incluso si no tienen exactamente las mismas dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TENSOR A: tensor([1, 2, 3])\n",
      "SHAPE: torch.Size([3])\n",
      "\n",
      "TENSOR B\n",
      "\n",
      " tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "\n",
      "SHAPE: torch.Size([3, 1])\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "TENSOR C:\n",
      "\n",
      " tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "SHAPE: torch.Size([3, 3]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([[1],\n",
    "                 [2],\n",
    "                 [3]])\n",
    "\n",
    "print(\"TENSOR A:\", a)\n",
    "print(\"SHAPE:\", a.shape)\n",
    "print(\"\\nTENSOR B\\n\\n\", b)\n",
    "print(\"\\nSHAPE:\", b.shape)\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Apply broadcasting\n",
    "c = a + b\n",
    "\n",
    "\n",
    "print(\"\\nTENSOR C:\\n\\n\", c)\n",
    "print(\"\\nSHAPE:\", c.shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 - Lógica y Comparaciones (Logic & Comparisons)\n",
    "\n",
    "Las operaciones lógicas son herramientas potentes para la preparación y el análisis de datos. Te permiten crear máscaras booleanas para filtrar, seleccionar o modificar tus datos basándote en condiciones específicas que tú definas.\n",
    "\n",
    "* **Operadores de Comparación**: Comparaciones elemento por elemento (element-wise) (`>`, `==`, `<`) que producen un tensor booleano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1739648576118,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "g4n6hAFsIp49",
    "outputId": "36efbe9f-62b7-4da3-f13b-c4114d6d72f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURES: tensor([20, 35, 19, 35, 42])\n",
      "--------------------------------------------------\n",
      "\n",
      "HOT (> 30 DEGREES): tensor([False,  True, False,  True,  True])\n",
      "COOL (<= 20 DEGREES): tensor([ True, False,  True, False, False])\n",
      "EXACTLY 35 DEGREES: tensor([False,  True, False,  True, False]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures = torch.tensor([20, 35, 19, 35, 42])\n",
    "print(\"TEMPERATURES:\", temperatures)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Comparison Operators (>, <, ==)\n",
    "\n",
    "# Use '>' (greater than) to find temperatures above 30\n",
    "is_hot = temperatures > 30\n",
    "\n",
    "# Use '<=' (less than or equal to) to find temperatures 20 or below\n",
    "is_cool = temperatures <= 20\n",
    "\n",
    "# Use '==' (equal to) to find temperatures exactly equal to 35\n",
    "is_35_degrees = temperatures == 35\n",
    "\n",
    "print(\"\\nHOT (> 30 DEGREES):\", is_hot)\n",
    "print(\"COOL (<= 20 DEGREES):\", is_cool)\n",
    "print(\"EXACTLY 35 DEGREES:\", is_35_degrees, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* **Operadores Lógicos**: Operaciones lógicas elemento por elemento (`&` para **AND**, `|` para **OR**) en tensores booleanos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1739649219118,
     "user": {
      "displayName": "Laurence Moroney",
      "userId": "17858265307580721507"
     },
     "user_tz": 480
    },
    "id": "hmEU32D4LDih",
    "outputId": "e4552510-be3e-4a58-b9bb-57c1344bb9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS MORNING: tensor([ True, False, False,  True])\n",
      "IS RAINING: tensor([False, False,  True,  True])\n",
      "--------------------------------------------------\n",
      "\n",
      "MORNING & (AND) RAINING: tensor([False, False, False,  True])\n",
      "MORNING | (OR) RAINING: tensor([ True, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "is_morning = torch.tensor([True, False, False, True])\n",
    "is_raining = torch.tensor([False, False, True, True])\n",
    "print(\"IS MORNING:\", is_morning)\n",
    "print(\"IS RAINING:\", is_raining)\n",
    "print(\"-\" * 50)\n",
    "\n",
    "### Logical Operators (&, |)\n",
    "\n",
    "# Use '&' (AND) to find when it's both morning and raining\n",
    "morning_and_raining = (is_morning & is_raining)\n",
    "\n",
    "# Use '|' (OR) to find when it's either morning or raining\n",
    "morning_or_raining = is_morning | is_raining\n",
    "\n",
    "print(\"\\nMORNING & (AND) RAINING:\", morning_and_raining)\n",
    "print(\"MORNING | (OR) RAINING:\", morning_or_raining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 - Estadísticas (Statistics)\n",
    "\n",
    "Calcular estadísticas como la media o la desviación estándar puede ser útil para entender tu conjunto de datos o para implementar ciertos tipos de normalización durante la fase de preparación de datos.\n",
    "\n",
    "* `torch.mean()`: Calcula la media de todos los elementos de un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "---------------------------------------------\n",
      "\n",
      "CALCULATED MEAN: tensor(30.) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([10.0, 20.0, 30.0, 40.0, 50.0])\n",
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the mean\n",
    "data_mean = data.mean()\n",
    "\n",
    "print(\"\\nCALCULATED MEAN:\", data_mean, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "* `torch.std()`: Calcula la desviación estándar de todos los elementos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "---------------------------------------------\n",
      "\n",
      "CALCULATED STD: tensor(15.8114) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA:\", data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "data_std = data.std()\n",
    "\n",
    "print(\"\\nCALCULATED STD:\", data_std, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 - Tipos de Datos (Data Types)\n",
    "\n",
    "Tan importante como la forma (shape) de un tensor es su tipo de dato. Las redes neuronales suelen realizar sus cálculos utilizando números de punto flotante de 32 bits (float32). Proporcionar datos del tipo incorrecto, como un entero, puede provocar errores de ejecución o comportamientos inesperados durante el entrenamiento. Es una buena práctica asegurarse de que los tensores tengan el tipo de dato correcto para tu modelo.\n",
    "\n",
    "* **Conversión de Tipo o Type Casting (`.int()`, etc.)**: Convierte un tensor de un tipo de dato a otro (por ejemplo, de float a integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: tensor([10., 20., 30., 40., 50.])\n",
      "DATA TYPE: torch.float32\n",
      "---------------------------------------------\n",
      "\n",
      "CASTED DATA: tensor([10, 20, 30, 40, 50], dtype=torch.int32)\n",
      "CASTED DATA TYPE torch.int32\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA:\", data)\n",
    "print(\"DATA TYPE:\", data.dtype)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Cast the tensor to a int type\n",
    "int_tensor = data.int()\n",
    "\n",
    "print(\"\\nCASTED DATA:\", int_tensor)\n",
    "print(\"CASTED DATA TYPE\", int_tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Ejercicios Opcionales (Optional Exercises)\n",
    "\n",
    "Ya has cubierto las herramientas esenciales para trabajar con tensores en PyTorch. La teoría proporciona el mapa, pero la práctica directa es lo que construye la verdadera confianza y habilidad. Los siguientes ejercicios opcionales son tu oportunidad para aplicar lo aprendido en escenarios prácticos, desde el análisis de datos de ventas hasta la ingeniería de nuevas características para un modelo de aprendizaje automático. Aquí es donde los conceptos realmente cobran vida, ¡así que sumérgete y pon a prueba tus nuevos conocimientos!\n",
    "\n",
    "### Ejercicio 1: Análisis de Datos de Ventas Mensuales\n",
    "\n",
    "Eres analista de datos en una empresa de comercio electrónico. Se te ha entregado un tensor que representa las ventas mensuales de tres productos diferentes durante un periodo de cuatro meses. Tu tarea es extraer información significativa de estos datos.\n",
    "\n",
    "El tensor `sales_data` está estructurado de la siguiente manera:\n",
    "\n",
    "* **Las filas** representan los **productos** (Producto A, Producto B, Producto C).\n",
    "* **Las columnas** representan los **meses** (Ene, Feb, Mar, Abr).\n",
    "\n",
    "**Tus objetivos son**:\n",
    "\n",
    "1. Calcular las ventas totales del **Producto B** (la segunda fila).\n",
    "2. Identificar qué meses tuvieron ventas **superiores a 130** para el **Producto C** (la tercera fila) utilizando una máscara booleana.\n",
    "3. Extraer los datos de ventas de todos los productos para los meses de **Feb y Mar** (las dos columnas centrales).\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solución (Haz clic aquí para expandir)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Calcular las ventas totales para el Producto B.\n",
    "total_sales_product_b = sales_data[1].sum()\n",
    "\n",
    "# 2. Encontrar los meses donde las ventas del Producto C fueron > 130.\n",
    "high_sales_mask_product_c = sales_data[2] > 130\n",
    "\n",
    "# 3. Obtener las ventas de Feb y Mar para todos los productos.\n",
    "sales_feb_mar = sales_data[:, 1:3]\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS DE VENTAS ORIGINALES:\n",
      "\n",
      " tensor([[100., 120., 130., 110.],\n",
      "        [ 90.,  95., 105., 125.],\n",
      "        [140., 115., 120., 150.]])\n",
      "---------------------------------------------\n",
      "\n",
      "Ventas Totales para el Producto B:                tensor(415.)\n",
      "\n",
      "Meses con ventas >130 para el Producto C (Máscara):  tensor([ True, False, False,  True])\n",
      "\n",
      "Ventas de Feb y Mar:\n",
      "\n",
      " tensor([[120., 130.],\n",
      "        [ 95., 105.],\n",
      "        [115., 120.]])\n"
     ]
    }
   ],
   "source": [
    "# Datos de ventas de 3 productos durante 4 meses\n",
    "sales_data = torch.tensor([[100, 120, 130, 110],   # Producto A\n",
    "                           [ 90,  95, 105, 125],   # Producto B\n",
    "                           [140, 115, 120, 150]    # Producto C\n",
    "                          ], dtype=torch.float32)\n",
    "\n",
    "print(\"DATOS DE VENTAS ORIGINALES:\\n\\n\", sales_data)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Calcular las ventas totales para el Producto B.\n",
    "total_sales_product_b = sales_data[1].sum()\n",
    "\n",
    "# 2. Encontrar los meses donde las ventas del Producto C fueron > 130.\n",
    "high_sales_mask_product_c = sales_data[2] > 130\n",
    "\n",
    "# 3. Obtener las ventas de Feb y Mar para todos los productos.\n",
    "sales_feb_mar = sales_data[:, 1:3]\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print(\"\\nVentas Totales para el Producto B:               \", total_sales_product_b)\n",
    "print(\"\\nMeses con ventas >130 para el Producto C (Máscara): \", high_sales_mask_product_c)\n",
    "print(\"\\nVentas de Feb y Mar:\\n\\n\", sales_feb_mar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "Ventas Totales para el Producto B:                       tensor(415.)\n",
    "\n",
    "Meses con ventas >130 para el Producto C (Máscara):      tensor([ True, False, False,  True])\n",
    "\n",
    "Ventas de Feb y Mar:\n",
    "\n",
    " tensor([[120., 130.],\n",
    "        [ 95., 105.],\n",
    "        [115., 120.]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Transformación de Lotes de Imágenes (Image Batch Transformation)\n",
    "\n",
    "Estás trabajando en un modelo de visión artificial y tienes un lote de 4 imágenes en escala de grises, cada una de un tamaño de 3x3 píxeles. Los datos están actualmente en un tensor con la forma `[4, 3, 3]`, que representa `[batch_size, height, width]`.\n",
    "\n",
    "Para el procesamiento con ciertos frameworks de deep learning, necesitas transformar estos datos al formato `[batch_size, channels, height, width]`. Dado que las imágenes son en escala de grises, **tendrás que**:\n",
    "\n",
    "1. Añadir una nueva dimensión de tamaño 1 en el índice 1 para representar el canal de color (channel).\n",
    "2. Después de añadir el canal, te das cuenta de que el modelo espera la forma `[batch_size, height, width, channels]`. Transpón el tensor para intercambiar la dimensión del canal con la última dimensión.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solución (Haz clic aquí para expandir)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Añadir una dimensión de canal en el índice 1.\n",
    "image_batch_with_channel = image_batch.unsqueeze(1)\n",
    "\n",
    "# 2. Trasponer el tensor para mover la dimensión del canal al final.\n",
    "# Intercambiar la dimensión 1 (channels) con la dimensión 3 (la última).\n",
    "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LOTE DE IMÁGENES EN ESCALA DE GRISES:\n",
      "\n",
      " tensor([[[0.6649, 0.4313, 0.2238],\n",
      "         [0.4656, 0.2469, 0.3819],\n",
      "         [0.9608, 0.7149, 0.2105]],\n",
      "\n",
      "        [[0.1026, 0.2332, 0.3063],\n",
      "         [0.6521, 0.2463, 0.2972],\n",
      "         [0.1306, 0.4289, 0.1610]],\n",
      "\n",
      "        [[0.5198, 0.9949, 0.8336],\n",
      "         [0.8663, 0.3064, 0.2282],\n",
      "         [0.5162, 0.4791, 0.1601]],\n",
      "\n",
      "        [[0.1155, 0.5101, 0.8326],\n",
      "         [0.8483, 0.7045, 0.8764],\n",
      "         [0.3790, 0.6014, 0.8257]]])\n",
      "FORMA DEL LOTE ORIGINAL: torch.Size([4, 3, 3])\n",
      "---------------------------------------------\n",
      "\n",
      "FORMA DESPUÉS DE UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
      "FORMA DESPUÉS DE TRANSPOSE: torch.Size([4, 3, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "# Un lote de 4 imágenes en escala de grises, cada una de 3x3\n",
    "image_batch = torch.rand(4, 3, 3)\n",
    "\n",
    "print(\"\\nLOTE DE IMÁGENES EN ESCALA DE GRISES:\\n\\n\", image_batch)\n",
    "\n",
    "print(\"FORMA DEL LOTE ORIGINAL:\", image_batch.shape)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Añadir una dimensión de canal en el índice 1.\n",
    "image_batch_with_channel = image_batch.unsqueeze(1)\n",
    "\n",
    "# 2. Trasponer el tensor para mover la dimensión del canal al final.\n",
    "# Intercambiar la dimensión 1 (channels) con la dimensión 3 (la última).\n",
    "image_batch_transposed = image_batch_with_channel.transpose(1, 3)\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "\n",
    "print(\"\\nFORMA DESPUÉS DE UNSQUEEZE:\", image_batch_with_channel.shape)\n",
    "print(\"FORMA DESPUÉS DE TRANSPOSE:\", image_batch_transposed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "SHAPE AFTER UNSQUEEZE: torch.Size([4, 1, 3, 3])\n",
    "SHAPE AFTER TRANSPOSE: torch.Size([4, 3, 3, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Combinación y Ponderación de Datos de Sensores (Combining and Weighting Sensor Data)\n",
    "\n",
    "Estás construyendo un sistema de monitoreo ambiental que utiliza dos sensores: uno para la temperatura y otro para la humedad. Recibes los datos de estos sensores como dos tensores 1D separados.\n",
    "\n",
    "**Tu tarea es**:\n",
    "\n",
    "1. **Concatenar** los dos tensores en un único tensor de `2x5`, donde la primera fila sean los datos de temperatura y la segunda los de humedad.\n",
    "2. Crear un tensor de pesos (`weights`) `torch.tensor([0.6, 0.4])`.\n",
    "3. Utilizar **broadcasting y multiplicación elemento por elemento** para aplicar estos pesos a los datos combinados de los sensores. Los datos de temperatura deben multiplicarse por 0.6 y los de humedad por 0.4.\n",
    "4. Finalmente, calcular el **promedio ponderado** para cada paso de tiempo **sumando** los valores ponderados a lo largo de `dim=0` y **dividiendo** por la suma de los pesos.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solución (Haz clic aquí para expandir)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Concatenar los dos tensores.\n",
    "# Nota: Primero necesitas usar unsqueeze para apilarlos verticalmente.\n",
    "combined_data = torch.cat((temperature.unsqueeze(0), humidity.unsqueeze(0)), dim=0)\n",
    "\n",
    "# 2. Crear el tensor de pesos.\n",
    "weights = torch.tensor([0.6, 0.4])\n",
    "\n",
    "# 3. Aplicar los pesos usando broadcasting.\n",
    "# Necesitas cambiar la forma (reshape) de los pesos a [2, 1] para hacer el broadcast a través de las columnas.\n",
    "weighted_data = combined_data * weights.unsqueeze(1)\n",
    "\n",
    "# 4. Calcular el promedio ponderado para cada paso de tiempo.\n",
    "#    (Un promedio real = suma ponderada / suma de los pesos)\n",
    "weighted_sum = torch.sum(weighted_data, dim=0)\n",
    "weighted_average = weighted_sum / torch.sum(weights)\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS DE TEMPERATURA:  tensor([22.5000, 23.1000, 21.9000, 22.8000, 23.5000])\n",
      "DATOS DE HUMEDAD:      tensor([55.2000, 56.4000, 54.8000, 57.1000, 56.8000])\n",
      "---------------------------------------------\n",
      "\n",
      "DATOS COMBINADOS (2x5):\n",
      "\n",
      " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
      "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
      "\n",
      "DATOS PONDERADOS:\n",
      "\n",
      " tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n",
      "        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n",
      "\n",
      "PROMEDIO PONDERADO: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n"
     ]
    }
   ],
   "source": [
    "# Lecturas de sensores (5 pasos de tiempo)\n",
    "temperature = torch.tensor([22.5, 23.1, 21.9, 22.8, 23.5])\n",
    "humidity = torch.tensor([55.2, 56.4, 54.8, 57.1, 56.8])\n",
    "\n",
    "print(\"DATOS DE TEMPERATURA: \", temperature)\n",
    "print(\"DATOS DE HUMEDAD:     \", humidity)\n",
    "print(\"-\" * 45)\n",
    "\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Concatenar los dos tensores.\n",
    "# Nota: Necesitas usar unsqueeze primero para apilarlos verticalmente.\n",
    "combined_data = torch.cat([temperature.unsqueeze(0), humidity.unsqueeze(0)], dim=0)\n",
    "\n",
    "# 2. Crear el tensor de pesos (weights).\n",
    "weights = torch.tensor([0.6, 0.4])\n",
    "\n",
    "# 3. Aplicar los pesos usando broadcasting.\n",
    "# Necesitas cambiar la forma de los pesos a [2, 1] para hacer el broadcast por columnas.\n",
    "weighted_data = combined_data * weights.unsqueeze(1)\n",
    "\n",
    "# 4. Calcular el promedio ponderado para cada paso de tiempo.\n",
    "#    (Un promedio real = suma ponderada / suma de los pesos)\n",
    "weighted_sum = weighted_data.sum(dim=0)\n",
    "weighted_average = weighted_sum / weights.sum()\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print(\"\\nDATOS COMBINADOS (2x5):\\n\\n\", combined_data)\n",
    "print(\"\\nDATOS PONDERADOS:\\n\\n\", weighted_data)\n",
    "print(\"\\nPROMEDIO PONDERADO:\", weighted_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "COMBINED DATA (2x5):\n",
    "\n",
    " tensor([[22.5000, 23.1000, 21.9000, 22.8000, 23.5000],\n",
    "        [55.2000, 56.4000, 54.8000, 57.1000, 56.8000]])\n",
    "\n",
    "WEIGHTED DATA:\n",
    "\n",
    " tensor([[13.5000, 13.8600, 13.1400, 13.6800, 14.1000],\n",
    "        [22.0800, 22.5600, 21.9200, 22.8400, 22.7200]])\n",
    "\n",
    "WEIGHTED AVERAGE: tensor([35.5800, 36.4200, 35.0600, 36.5200, 36.8200])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Ingeniería de Características para Tarifas de Taxi (Feature Engineering for Taxi Fares)\n",
    "\n",
    "Estás trabajando con un conjunto de datos de viajes en taxi. Tienes un tensor, `trip_data`, donde cada fila es un viaje y las columnas representan **[distancia (km), hora_del_día (24h)]**.\n",
    "\n",
    "**Tu objetivo** es crear una nueva característica binaria llamada `is_rush_hour_long_trip`. Esta característica debe ser `True` (o `1`) solo si un viaje cumple con **ambos** de los siguientes criterios:\n",
    "\n",
    "* Es un **viaje largo** (distancia > 10 km).\n",
    "* Ocurre durante una **hora punta** (8-10 AM o 5-7 PM, es decir, `[8, 10)` o `[17, 19)`).\n",
    "\n",
    "Para lograr esto, necesitarás:\n",
    "\n",
    "1. **Segmentar (Slice)** el tensor `trip_data` para aislar las columnas de `distance` y `hour`.\n",
    "2. Usar **operadores lógicos y de comparación** para crear máscaras booleanas para cada condición (viaje largo, hora punta matutina, hora punta vespertina).\n",
    "3. Combinar estas máscaras para crear la característica final `is_rush_hour_long_trip`.\n",
    "4. **Cambiar la forma (Reshape)** de este nuevo tensor de característica 1D a un vector de columna 2D y convertir su tipo de dato a float para que pueda combinarse con los datos originales.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary><span style=\"color:green;\"><strong>Solución (Haz clic aquí para expandir)</strong></span></summary>\n",
    "\n",
    "```python\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Segmentar el tensor principal para obtener tensores 1D para cada característica.\n",
    "distances = trip_data[:, 0]\n",
    "hours = trip_data[:, 1]\n",
    "\n",
    "# 2. Crear máscaras booleanas para cada condición.\n",
    "is_long_trip = distances > 10.0\n",
    "is_morning_rush = (hours >= 8.0) & (hours < 10.0)\n",
    "is_evening_rush = (hours >= 17.0) & (hours < 19.0)\n",
    "\n",
    "# 3. Combinar máscaras para identificar viajes largos en hora punta.\n",
    "# Un viaje es un \"rush hour long trip\" si es (hora punta matutina O vespertina) Y un viaje largo.\n",
    "is_rush_hour_long_trip_mask = (is_morning_rush | is_evening_rush) & is_long_trip\n",
    "\n",
    "# 4. Cambiar la forma de la nueva característica a un vector de columna y convertir a float.\n",
    "new_feature_col = is_rush_hour_long_trip_mask.float().unsqueeze(1)\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATOS DE VIAJES ORIGINALES (Distancia, Hora):\n",
      "\n",
      " tensor([[ 5.3000,  7.0000],\n",
      "        [12.1000,  9.0000],\n",
      "        [15.5000, 13.0000],\n",
      "        [ 6.7000, 18.0000],\n",
      "        [ 2.4000, 20.0000],\n",
      "        [11.8000, 17.0000],\n",
      "        [ 9.0000,  9.0000],\n",
      "        [14.2000,  8.0000]])\n",
      "-------------------------------------------------------\n",
      "\n",
      "MÁSCARA 'IS RUSH HOUR LONG TRIP':  tensor([False, False, False,  True, False,  True, False, False])\n",
      "\n",
      "COLUMNA DE NUEVA CARACTERÍSTICA (Redimensionada):\n",
      "\n",
      " tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]])\n",
      "\n",
      "DATOS MEJORADOS (con la nueva característica al final):\n",
      "\n",
      " tensor([[ 5.3000,  7.0000,  0.0000],\n",
      "        [12.1000,  9.0000,  0.0000],\n",
      "        [15.5000, 13.0000,  0.0000],\n",
      "        [ 6.7000, 18.0000,  1.0000],\n",
      "        [ 2.4000, 20.0000,  0.0000],\n",
      "        [11.8000, 17.0000,  1.0000],\n",
      "        [ 9.0000,  9.0000,  0.0000],\n",
      "        [14.2000,  8.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Datos de 8 viajes en taxi: [distancia, hora_del_día]\n",
    "trip_data = torch.tensor([\n",
    "    [5.3, 7],   # Ni hora punta, ni largo\n",
    "    [12.1, 9],  # Hora punta mañana, viaje largo -> RUSH HOUR LONG\n",
    "    [15.5, 13], # Ni hora punta, viaje largo\n",
    "    [6.7, 18],  # Hora punta tarde, no largo\n",
    "    [2.4, 20],  # Ni hora punta, ni largo\n",
    "    [11.8, 17], # Hora punta tarde, viaje largo -> RUSH HOUR LONG\n",
    "    [9.0, 9],   # Hora punta mañana, no largo\n",
    "    [14.2, 8]   # Hora punta mañana, viaje largo -> RUSH HOUR LONG\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "print(\"DATOS DE VIAJES ORIGINALES (Distancia, Hora):\\n\\n\", trip_data)\n",
    "print(\"-\" * 55)\n",
    "\n",
    "\n",
    "### EMPIEZA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "# 1. Segmentar el tensor principal para obtener tensores 1D para cada característica.\n",
    "distances = trip_data[:, 0]\n",
    "hours = trip_data[:, 1]\n",
    "\n",
    "# 2. Crear máscaras booleanas para cada condición.\n",
    "is_long_trip = hours > 10\n",
    "is_morning_rush = ((hours >= 7) & (hours <= 9))\n",
    "is_evening_rush = ((hours >= 16) & (hours <= 19))\n",
    "\n",
    "# 3. Combinar máscaras para identificar viajes largos en hora punta.\n",
    "# Un viaje es largo en hora punta si es (punta mañana O punta tarde) Y un viaje largo.\n",
    "is_rush_hour_long_trip_mask = is_long_trip & (is_morning_rush | is_evening_rush)\n",
    "\n",
    "# 4. Cambiar la forma de la nueva característica a un vector de columna y convertir a float.\n",
    "new_feature_col = is_rush_hour_long_trip_mask.unsqueeze(1).float()\n",
    "\n",
    "### TERMINA EL CÓDIGO AQUÍ ###\n",
    "\n",
    "print(\"\\nMÁSCARA 'IS RUSH HOUR LONG TRIP': \", is_rush_hour_long_trip_mask)\n",
    "print(\"\\nCOLUMNA DE NUEVA CARACTERÍSTICA (Redimensionada):\\n\\n\", new_feature_col)\n",
    "\n",
    "# Ahora puedes concatenar esta nueva característica a los datos originales\n",
    "enhanced_trip_data = torch.cat((trip_data, new_feature_col), dim=1)\n",
    "print(\"\\nDATOS MEJORADOS (con la nueva característica al final):\\n\\n\", enhanced_trip_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "\n",
    "```\n",
    "'IS RUSH HOUR LONG TRIP' MASK:  tensor([False,  True, False, False, False,  True, False,  True])\n",
    "\n",
    "NEW FEATURE COLUMN (Reshaped):\n",
    "\n",
    " tensor([[0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.]])\n",
    "\n",
    "ENHANCED DATA (with new feature at the end):\n",
    "\n",
    " tensor([[ 5.3000,  7.0000,  0.0000],\n",
    "        [12.1000,  9.0000,  1.0000],\n",
    "        [15.5000, 13.0000,  0.0000],\n",
    "        [ 6.7000, 18.0000,  0.0000],\n",
    "        [ 2.4000, 20.0000,  0.0000],\n",
    "        [11.8000, 17.0000,  1.0000],\n",
    "        [ 9.0000,  9.0000,  0.0000],\n",
    "        [14.2000,  8.0000,  1.0000]])\n",
    "```        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión (Conclusion)\n",
    "\n",
    "¡Felicitaciones por completar este laboratorio! Ahora has trabajado con los bloques de construcción fundamentales de PyTorch. Comenzaste desde cero y aprendiste a crear, redimensionar, combinar y consultar tensores de diversas maneras.\n",
    "\n",
    "Las habilidades que has desarrollado aquí son esenciales para todo practicante de machine learning. La aritmética elemento por elemento (element-wise) y el broadcasting que practicaste son precisamente la forma en que una red neuronal aplica eficientemente pesos (weights) y sesgos (biases) a lotes enteros de datos a la vez. Las técnicas de redimensionamiento como `unsqueeze` y `squeeze` son las que te permiten preparar un solo punto de datos para un modelo que espera un lote (batch), y luego limpiar la salida después. Estos no son solo ejercicios abstractos; son las operaciones diarias necesarias para construir y depurar modelos de deep learning efectivos.\n",
    "\n",
    "Con este sólido conocimiento de los tensores, estás plenamente preparado para pasar a la siguiente etapa: construir y entrenar redes neuronales para resolver problemas aún más complejos. Cada modelo que construyas de ahora en adelante se apoyará sobre esta base."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOorK7XLr3MfwWQG/E40ryg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pytorch-for-deep-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
